<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="pt" xml:lang="pt"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Resolvendo Captchas - Apêndice A — Pacotes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 1em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./bibliografia.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "Nenhum resultado",
    "search-matching-documents-text": "documentos correspondentes",
    "search-copy-link-title": "Copiar link para a busca",
    "search-hide-matches-text": "Esconder correspondências adicionais",
    "search-more-match-text": "mais correspondência neste documento",
    "search-more-matches-text": "mais correspondências neste documento",
    "search-clear-button-title": "Limpar",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar"
  }
}</script>
<script src="site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="site_libs/quarto-diagram/mermaid.css" rel="stylesheet">


<meta name="citation_title" content="[Apêndice  A — Pacotes]{#sec-pacote .quarto-section-identifier}">
<meta name="citation_language" content="pt">
<meta name="citation_reference" content="citation_title=Recognizing objects in adversarial clutter: Breaking a visual CAPTCHA;,citation_author=Greg Mori;,citation_author=Jitendra Malik;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_volume=1;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Recognizing objects in adversarial clutter: Breaking a visual CAPTCHA;,citation_author=Greg Mori;,citation_author=Jitendra Malik;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_volume=1;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Designing human friendly human interaction proofs (HIPs);,citation_author=Kumar Chellapilla;,citation_author=Kevin Larson;,citation_author=Patrice Simard;,citation_author=Mary Czerwinski;,citation_publication_date=2005-04-02;,citation_cover_date=2005-04-02;,citation_year=2005;,citation_fulltext_html_url=https://doi.org/10.1145/1054972.1055070;,citation_doi=10.1145/1054972.1055070;,citation_conference=Association for Computing Machinery;,citation_series_title=CHI ’05;">
<meta name="citation_reference" content="citation_title=Using machine learning to break visual human interaction proofs (HIPs);,citation_author=Kumar Chellapilla;,citation_author=Patrice Simard;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_volume=17;,citation_journal_title=Advances in neural information processing systems;">
<meta name="citation_reference" content="citation_title=Multi-digit number recognition from street view imagery using deep convolutional neural networks;,citation_author=Ian J. Goodfellow;,citation_author=Yaroslav Bulatov;,citation_author=Julian Ibarz;,citation_author=Sacha Arnoud;,citation_author=Vinay Shet;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_journal_title=arXiv preprint arXiv:1312.6082;">
<meta name="citation_reference" content="citation_title=Deep learning;,citation_author=Yann LeCun;,citation_author=Yoshua Bengio;,citation_author=Geoffrey Hinton;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=7553;,citation_volume=521;,citation_journal_title=nature;">
<meta name="citation_reference" content="citation_title=Deep learning;,citation_author=Yann LeCun;,citation_author=Yoshua Bengio;,citation_author=Geoffrey Hinton;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=7553;,citation_volume=521;,citation_journal_title=nature;">
<meta name="citation_reference" content="citation_title=Generative adversarial networks;,citation_author=Ian Goodfellow;,citation_author=Jean Pouget-Abadie;,citation_author=Mehdi Mirza;,citation_author=Bing Xu;,citation_author=David Warde-Farley;,citation_author=Sherjil Ozair;,citation_author=Aaron Courville;,citation_author=Yoshua Bengio;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=11;,citation_volume=63;,citation_journal_title=Communications of the ACM;">
<meta name="citation_reference" content="citation_title=Generative Adversarial Networks;,citation_author=Ian J. Goodfellow;,citation_author=Jean Pouget-Abadie;,citation_author=Mehdi Mirza;,citation_author=Bing Xu;,citation_author=David Warde-Farley;,citation_author=Sherjil Ozair;,citation_author=Aaron Courville;,citation_author=Yoshua Bengio;,citation_doi=10.48550/arXiv.1406.2661;">
<meta name="citation_reference" content="citation_title=A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs;,citation_author=Dileep George;,citation_author=Wolfgang Lehrach;,citation_author=Ken Kansky;,citation_author=Miguel Lázaro-Gredilla;,citation_author=Christopher Laan;,citation_author=Bhaskara Marthi;,citation_author=Xinghua Lou;,citation_author=Zhaoshi Meng;,citation_author=Yi Liu;,citation_author=Huayan Wang;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=6368;,citation_volume=358;,citation_journal_title=Science;">
<meta name="citation_reference" content="citation_title=Yet another text captcha solver: A generative adversarial network based approach;,citation_author=Guixin Ye;,citation_author=Zhanyong Tang;,citation_author=Dingyi Fang;,citation_author=Zhanxing Zhu;,citation_author=Yansong Feng;,citation_author=Pengfei Xu;,citation_author=Xiaojiang Chen;,citation_author=Zheng Wang;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Yet another text captcha solver: A generative adversarial network based approach;,citation_author=Guixin Ye;,citation_author=Zhanyong Tang;,citation_author=Dingyi Fang;,citation_author=Zhanxing Zhu;,citation_author=Yansong Feng;,citation_author=Pengfei Xu;,citation_author=Xiaojiang Chen;,citation_author=Zheng Wang;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Make complex captchas simple: a fast text captcha solver based on a small number of samples;,citation_author=Yao Wang;,citation_author=Yuliang Wei;,citation_author=Mingjin Zhang;,citation_author=Yang Liu;,citation_author=Bailing Wang;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_volume=578;,citation_journal_title=Information Sciences;">
<meta name="citation_reference" content="citation_title=A survey of CAPTCHA technologies to distinguish between human and computer;,citation_author=Xin Xu;,citation_author=Lei Liu;,citation_author=Bo Li;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=408;,citation_journal_title=Neurocomputing;">
<meta name="citation_reference" content="citation_title=Adversarial examples: Attacks and defenses for deep learning;,citation_author=Xiaoyong Yuan;,citation_author=Pan He;,citation_author=Qile Zhu;,citation_author=Xiaolin Li;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=9;,citation_volume=30;,citation_journal_title=IEEE transactions on neural networks and learning systems;">
<meta name="citation_reference" content="citation_title=Regularizing deep neural networks by noise: Its interpretation and optimization;,citation_author=Hyeonwoo Noh;,citation_author=Tackgeun You;,citation_author=Jonghwan Mun;,citation_author=Bohyung Han;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_volume=30;,citation_journal_title=Advances in Neural Information Processing Systems;">
<meta name="citation_reference" content="citation_title=reCAPTCHA: Human-Based Character Recognition via Web Security Measures;,citation_author=Luis Ahn;,citation_author=Benjamin Maurer;,citation_author=Colin McMillen;,citation_author=David Abraham;,citation_author=Manuel Blum;,citation_publication_date=2008-09-12;,citation_cover_date=2008-09-12;,citation_year=2008;,citation_fulltext_html_url=https://www.science.org/doi/10.1126/science.1160379;,citation_issue=5895;,citation_doi=10.1126/science.1160379;,citation_volume=321;,citation_language=en;,citation_journal_title=Science;">
<meta name="citation_reference" content="citation_title=Reinforcement learning: An introduction;,citation_author=Richard S. Sutton;,citation_author=Andrew G. Barto;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Deep Generative Positive-Unlabeled Learning under Selection Bias;,citation_author=Byeonghu Na;,citation_author=Hyemi Kim;,citation_author=Kyungwoo Song;,citation_author=Weonyoung Joo;,citation_author=Yoon-Yeong Kim;,citation_author=Il-Chul Moon;,citation_publication_date=2020-10-19;,citation_cover_date=2020-10-19;,citation_year=2020;,citation_fulltext_html_url=https://doi.org/10.1145/3340531.3411971;,citation_doi=10.1145/3340531.3411971;,citation_conference=Association for Computing Machinery;,citation_series_title=CIKM ’20;">
<meta name="citation_reference" content="citation_title=Análise de sobrevivência aplicada;,citation_author=Enrico Antonio Colosimo;,citation_author=Suely Ruiz Giolo;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;">
<meta name="citation_reference" content="citation_title=A brief introduction to weakly supervised learning;,citation_author=Zhi-Hua Zhou;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=1;,citation_volume=5;,citation_journal_title=National science review;">
<meta name="citation_reference" content="citation_title=Computing machinery and intelligence;,citation_author=Alan M. Turing;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Telling humans and computers apart automatically or how lazy cryptographers do AI (Tech. Rep. No. CMU-CS-02-117);,citation_author=L. Ahn;,citation_author=M. Blum;,citation_author=J. Langford;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_fulltext_html_url=http://reports-archive.adm.cs.cmu.edu/anon/2002/CMU-CS-02-117.pdf;">
<meta name="citation_reference" content="citation_title=Inaccessibility of CAPTCHA;,citation_fulltext_html_url=https://www.w3.org/TR/turingtest/;">
<meta name="citation_reference" content="citation_title=Estado brasileiro e transparência avaliando a aplicação da Lei de Acesso à Informação;,citation_author=Gregory Michener;,citation_author=Luiz Fernando Moncau;,citation_author=Rafael Braem Velasco;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=Open data in science;,citation_author=Peter Murray-Rust;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_journal_title=Nature Precedings;">
<meta name="citation_reference" content="citation_title=Observatório da insolvência: Rio de Janeiro;,citation_fulltext_html_url=https://abj.org.br/pesquisas/obsrjrj/;">
<meta name="citation_reference" content="citation_title=Tempo dos processos relacionados à adoção;,citation_fulltext_html_url=https://abj.org.br/pesquisas/adocao/;">
<meta name="citation_reference" content="citation_title=Diagnóstico do Contencioso Tributário Administrativo;,citation_fulltext_html_url=https://abj.org.br/pesquisas/bid-tributario/;">
<meta name="citation_reference" content="citation_title=Diagnóstico do Contencioso Tributário Administrativo;,citation_fulltext_html_url=https://abj.org.br/pesquisas/bid-tributario/;">
<meta name="citation_reference" content="citation_title=Web scraping;,citation_author=Bo Zhao;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://www.researchgate.net/profile/Bo-Zhao-3/publication/317177787_Web_Scraping/links/5c293f85a6fdccfc7073192f/Web-Scraping.pdf;,citation_journal_title=Encyclopedia of big data;">
<meta name="citation_reference" content="citation_title=A brief introduction to weakly supervised learning;,citation_author=Zhi-Hua Zhou;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=1;,citation_volume=5;,citation_journal_title=National science review;">
<meta name="citation_reference" content="citation_title=Semi-supervised learning literature survey;,citation_author=Xiaojin Jerry Zhu;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;">
<meta name="citation_reference" content="citation_title=A note on learning from multiple-instance examples;,citation_author=Avrim Blum;,citation_author=Adam Kalai;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=1;,citation_volume=30;,citation_journal_title=Machine learning;">
<meta name="citation_reference" content="citation_title=Learning with multiple labels;,citation_author=Rong Jin;,citation_author=Zoubin Ghahramani;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_volume=15;,citation_journal_title=Advances in neural information processing systems;">
<meta name="citation_reference" content="citation_title=Gradient-based learning applied to document recognition;,citation_author=Yann LeCun;,citation_author=Léon Bottou;,citation_author=Yoshua Bengio;,citation_author=Patrick Haffner;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=11;,citation_volume=86;,citation_journal_title=Proceedings of the IEEE;">
<meta name="citation_reference" content="citation_title=Generalized linear models;,citation_author=John Ashworth Nelder;,citation_author=Robert WM Wedderburn;,citation_publication_date=1972;,citation_cover_date=1972;,citation_year=1972;,citation_issue=3;,citation_volume=135;,citation_journal_title=Journal of the Royal Statistical Society: Series A (General);">
<meta name="citation_reference" content="citation_title=Hierarchical Text-Conditional Image Generation with CLIP Latents;,citation_author=Aditya Ramesh;,citation_author=Prafulla Dhariwal;,citation_author=Alex Nichol;,citation_author=Casey Chu;,citation_author=Mark Chen;,citation_doi=10.48550/arXiv.2204.06125;">
<meta name="citation_reference" content="citation_title=Feature engineering and selection: A practical approach for predictive models;,citation_author=Max Kuhn;,citation_author=Kjell Johnson;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;">
<meta name="citation_reference" content="citation_title=Understanding dropout;,citation_author=Pierre Baldi;,citation_author=Peter J. Sadowski;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_volume=26;,citation_journal_title=Advances in neural information processing systems;">
<meta name="citation_reference" content="citation_title=A review on ensembles for the class imbalance problem: bagging-, boosting-, and hybrid-based approaches;,citation_author=Mikel Galar;,citation_author=Alberto Fernandez;,citation_author=Edurne Barrenechea;,citation_author=Humberto Bustince;,citation_author=Francisco Herrera;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=4;,citation_volume=42;,citation_journal_title=IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews);">
<meta name="citation_reference" content="citation_title=Adam: A Method for Stochastic Optimization;,citation_author=Diederik P. Kingma;,citation_author=Jimmy Ba;,citation_doi=10.48550/arXiv.1412.6980;">
<meta name="citation_reference" content="citation_title=Efficient backprop;,citation_author=Yann A. LeCun;,citation_author=Léon Bottou;,citation_author=Genevieve B. Orr;,citation_author=Klaus-Robert Müller;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Learning from partial labels;,citation_author=Timothee Cour;,citation_author=Ben Sapp;,citation_author=Ben Taskar;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=12;,citation_journal_title=The Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Provably consistent partial-label learning;,citation_author=Lei Feng;,citation_author=Jiaqi Lv;,citation_author=Bo Han;,citation_author=Miao Xu;,citation_author=Gang Niu;,citation_author=Xin Geng;,citation_author=Bo An;,citation_author=Masashi Sugiyama;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=33;,citation_journal_title=Advances in Neural Information Processing Systems;">
<meta name="citation_reference" content="citation_title=Logistic regression for partial labels;,citation_author=Yves Grandvalet;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;">
<meta name="citation_reference" content="citation_title=Learning from ambiguously labeled examples;,citation_author=Eyke Hüllermeier;,citation_author=Jürgen Beringer;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=5;,citation_volume=10;,citation_journal_title=Intelligent Data Analysis;">
<meta name="citation_reference" content="citation_title=A conditional multinomial mixture model for superset label learning;,citation_author=Liping Liu;,citation_author=Thomas Dietterich;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_volume=25;,citation_journal_title=Advances in neural information processing systems;">
<meta name="citation_reference" content="citation_title=Learning from complementary labels;,citation_author=Takashi Ishida;,citation_author=Gang Niu;,citation_author=Weihua Hu;,citation_author=Masashi Sugiyama;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_volume=30;,citation_journal_title=Advances in neural information processing systems;">
<meta name="citation_reference" content="citation_title=Learning from complementary labels;,citation_author=Takashi Ishida;,citation_author=Gang Niu;,citation_author=Weihua Hu;,citation_author=Masashi Sugiyama;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_volume=30;,citation_journal_title=Advances in neural information processing systems;">
<meta name="citation_reference" content="citation_title=magick: Advanced Graphics and Image-Processing in R;,citation_author=Jeroen Ooms;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://CRAN.R-project.org/package=magick;">
<meta name="citation_reference" content="citation_title=magick: Advanced Graphics and Image-Processing in R;,citation_author=Jeroen Ooms;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://CRAN.R-project.org/package=magick;">
<meta name="citation_reference" content="citation_title=Learning with biased complementary labels;,citation_author=Xiyu Yu;,citation_author=Tongliang Liu;,citation_author=Mingming Gong;,citation_author=Dacheng Tao;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Learning with multiple complementary labels;,citation_author=Lei Feng;,citation_author=Takuo Kaneko;,citation_author=Bo Han;,citation_author=Gang Niu;,citation_author=Bo An;,citation_author=Masashi Sugiyama;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_conference=PMLR;">
<meta name="citation_reference" content="citation_title=Web scraping;,citation_author=Bo Zhao;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://www.researchgate.net/profile/Bo-Zhao-3/publication/317177787_Web_Scraping/links/5c293f85a6fdccfc7073192f/Web-Scraping.pdf;,citation_journal_title=Encyclopedia of big data;">
<meta name="citation_reference" content="citation_title=xml2: Parse XML;,citation_author=Hadley Wickham;,citation_author=Jim Hester;,citation_author=Jeroen Ooms;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://CRAN.R-project.org/package=xml2;">
<meta name="citation_reference" content="citation_title=stringr: Simple, Consistent Wrappers for Common String Operations;,citation_author=Hadley Wickham;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=stringr;">
<meta name="citation_reference" content="citation_title=rvest: Easily Harvest (Scrape) Web Pages;,citation_author=Hadley Wickham;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=rvest;">
<meta name="citation_reference" content="citation_title=Captcha and Its Techniques: A Review;,citation_author=Kiranjot Kaur;,citation_author=Sunny Behal;,citation_publication_date=2014-01-01;,citation_cover_date=2014-01-01;,citation_year=2014;,citation_volume=5;,citation_journal_title=International Journal of Computer Science and Information Technologies,;">
<meta name="citation_reference" content="citation_title=Multivariate binomial/multinomial control chart;,citation_author=Jian Li;,citation_author=Fugee Tsung;,citation_author=Changliang Zou;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=5;,citation_volume=46;,citation_journal_title=IIE Transactions;">
<meta name="citation_reference" content="citation_title=Batch normalization: Accelerating deep network training by reducing internal covariate shift;,citation_author=Sergey Ioffe;,citation_author=Christian Szegedy;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference=PMLR;">
<meta name="citation_reference" content="citation_title=torch: Tensors and Neural Networks with ’GPU’ Acceleration;,citation_author=Daniel Falbel;,citation_author=Javier Luraschi;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=torch;">
<meta name="citation_reference" content="citation_title=luz: Higher Level ’API’ for ’torch’;,citation_author=Daniel Falbel;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=luz;">
<meta name="citation_reference" content="citation_title=torchvision: Models, Datasets and Transformations for Images;,citation_author=Daniel Falbel;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=torchvision;">
<meta name="citation_reference" content="citation_title=R: A Language and Environment for Statistical Computing;,citation_author=R Core Team;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://www.R-project.org/;">
<meta name="citation_reference" content="citation_title=Feature engineering and selection: A practical approach for predictive models;,citation_author=Max Kuhn;,citation_author=Kjell Johnson;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;">
<meta name="citation_reference" content="citation_title=tensorflow: R Interface to ’TensorFlow’;,citation_author=JJ Allaire;,citation_author=Yuan Tang;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=tensorflow;">
<meta name="citation_reference" content="citation_title=decryptr: An extensible API for breaking captchas;,citation_author=Julio Trecenti;,citation_author=Caio Lente;,citation_author=Daniel Falbel;,citation_author=Milene Farhat;,citation_author=Beatriz Vianna;,citation_author=Evelin Angelica;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=reticulate: Interface to ’Python’;,citation_author=Kevin Ushey;,citation_author=JJ Allaire;,citation_author=Yuan Tang;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=reticulate;">
<meta name="citation_reference" content="citation_title=torch: Tensors and Neural Networks with ’GPU’ Acceleration;,citation_author=Daniel Falbel;,citation_author=Javier Luraschi;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=torch;">
<meta name="citation_reference" content="citation_title=piggyback: Managing Larger Data on a GitHub Repository;,citation_author=Carl Boettiger;,citation_author=Tan Ho;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=piggyback;">
<meta name="citation_reference" content="citation_title=usethis: Automate Package and Project Setup;,citation_author=Hadley Wickham;,citation_author=Jennifer Bryan;,citation_author=Malcolm Barrett;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=usethis;">
<meta name="citation_reference" content="citation_title=piggyback: Managing Larger Data on a GitHub Repository;,citation_author=Carl Boettiger;,citation_author=Tan Ho;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=piggyback;">
<meta name="citation_reference" content="citation_title=Hierarchical Text-Conditional Image Generation with CLIP Latents;,citation_author=Aditya Ramesh;,citation_author=Prafulla Dhariwal;,citation_author=Alex Nichol;,citation_author=Casey Chu;,citation_author=Mark Chen;,citation_doi=10.48550/arXiv.2204.06125;">
<meta name="citation_reference" content="citation_title=AVA: A large-scale database for aesthetic visual analysis;,citation_author=Naila Murray;,citation_author=Luca Marchesotti;,citation_author=Florent Perronnin;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference=IEEE;">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Apêndice A — Pacotes</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Resolvendo Captchas</a> 
        <div class="sidebar-tools-main">
    <a href="./Resolvendo-Captchas.pdf" title="Download PDF" class="sidebar-tool px-1"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Sobre este documento</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introducao.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introdução</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./metodologia.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Metodologia</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./resultados.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Resultados</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conclusoes.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Conclusões</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bibliografia.html" class="sidebar-item-text sidebar-link">Bibliografia</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Apêndices</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pacote.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Pacotes</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Índice</h2>
   
  <ul>
  <li><a href="#sec-pacote-captcha" id="toc-sec-pacote-captcha" class="nav-link active" data-scroll-target="#sec-pacote-captcha">Pacote captcha</a>
  <ul class="collapse">
  <li><a href="#uso-básico" id="toc-uso-básico" class="nav-link" data-scroll-target="#uso-básico">Uso básico</a></li>
  <li><a href="#sec-ap-modelagem" id="toc-sec-ap-modelagem" class="nav-link" data-scroll-target="#sec-ap-modelagem">Modelagem</a></li>
  <li><a href="#sec-captcha-do-zero" id="toc-sec-captcha-do-zero" class="nav-link" data-scroll-target="#sec-captcha-do-zero">Resolvendo um novo Captcha do zero</a></li>
  </ul></li>
  <li><a href="#sec-pacote-download" id="toc-sec-pacote-download" class="nav-link" data-scroll-target="#sec-pacote-download">Pacote captchaDownload</a></li>
  <li><a href="#sec-pacote-oracle" id="toc-sec-pacote-oracle" class="nav-link" data-scroll-target="#sec-pacote-oracle">Pacote captchaOracle</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-pacote" class="quarto-section-identifier d-none d-lg-block">Apêndice A — Pacotes</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>Este apêndice foi construído para mostrar a estrutura do pacote e suas funcionalidades, mas também um pouco da história. O pacote <code>{captcha}</code> é fruto de um trabalho da comunidade e o trabalho de modelagem de Captchas usando técnicas de <em>deep learning</em> começou alguns anos antes do início da tese de doutorado.</p>
<p>O trabalho de resolução de Captchas pelo autor da tese surgiu no ano de 2016. Como foi comentado na introdução da tese, é muito comum se deparar com desafios de Captchas ao raspar dados do judiciário, já que os dados não são abertos.</p>
<p>O primeiro Captcha a ser investigado foi o do sistema e-SAJ. O desafio era utlizado no site do TJSP que, depois de alguns anos, passou a utilizar o sistema reCaptcha. O Captcha do SAJ faz parte da tese, mas tem como fonte de dados o TJBA, que continua utilizando o desafio até o momento que os sites foram investigados pela última vez, em setembro de 2022.</p>
<p>A primeira abordagem para resolver o Captcha do e-SAJ foi utilizando heurísticas para separar as letras, em 2016. Infelizmente o pacote original, chamado <code>{captchasaj}</code>, foi removido da <em>internet</em>, mas um código legado construído para o TJRS está disponível <a href="https://github.com/decryptr/captchaTJRS/blob/master/R/tools.R">neste link</a>. Nessa abordagem, as letras primeiro são segmentadas, alimentando um modelo de florestas aleatórias que considera os pixels da imagem como variáveis preditoras e a letra como resposta. Esses trabalhos tiveram contribuições importantes de Fernando Corrêa e Athos Damiani.</p>
<p>A segunda abordagem para resolver os Captchas foi utilizando o áudio, também em 2016. O código para resolver o Captcha da RFB utilizando áudio está disponível <a href="https://github.com/decryptr/captchaReceitaAudio">neste link</a>. A ideia de resolução era parecida, passando pelo procedimento de segmentação e depois de modelagem, mas tinha um passo intermediário de processamento envolvendo engenharia de <em>features</em> <span class="citation" data-cites="kuhn2019">(<a href="bibliografia.html#ref-kuhn2019" role="doc-biblioref">KUHN; JOHNSON, 2019</a>)</span>. O trabalho teve contribuições importantes de Athos Damiani.</p>
<p>Com o advento da ferramenta TensorFlow para o R <span class="citation" data-cites="tensorflow">(<a href="bibliografia.html#ref-tensorflow" role="doc-biblioref">ALLAIRE; TANG, 2022</a>)</span>, os modelos passaram a utilizar modelos de redes neurais. No início, por falta de conhecimento da área, a arquitetura das redes era demasiadamente complexa. Depois que os primeiros modelos começaram a funcionar, notou-se que as etapas de pré-processamento com segmentação e algumas camadas das redes eram desnecessárias para ajustar os modelos. Essa parte teve grande contribuição de Daniel Falbel, que foi a pessoa que introduziu o TensorFlow e a área de <em>deep learning</em> aos colegas.</p>
<p>Depois de resolver com sucesso alguns Captchas, notou-se que seria possível criar um ambiente completo de modelagem de Captchas. Isso deu origem ao pacote <code>{decryptr}</code> <span class="citation" data-cites="decryptr">(<a href="bibliografia.html#ref-decryptr" role="doc-biblioref">TRECENTI et al., 2022</a>)</span>, que foi construído em 2017 durante uma <em>datathon</em> (uma maratona de programação), na casa de amigos. O trabalho teve grandes contribuições de Caio Lente, com participação das colegas de faculdade Milene Farhat e Beatriz Vianna.</p>
<p>Com o passar do tempo, o pacote <code>{decryptr}</code> ficou cada vez mais estável, funcionando como dependência de várias ferramentas utilizadas nos trabalhos de jurimetria. O pacote também ganhou um site: &lt;https://decryptr.xyz/&gt; e uma API com acesso gratuito, precisando apenas de uma chave de acesso. A ferramenta ficou bastante popular, com <a href="https://github.com/decryptr/decryptr">178 estrelas no GitHub</a> no mês de dezembro de 2022. Essas ferramentas envolveram contribuições principalmente de Caio Lente e Daniel Falbel.</p>
<p>A construção do pacote <code>{captcha}</code> separada do <code>{decryptr}</code> se deu por dois motivos. Primeiro, o pacote <code>{decryptr}</code>, por ser o primeiro a tratar do assunto, possui muitos códigos legado e dificuldades de instalação por conta da dependência do python, necessário para o funcionamento do TensorFlow, que é chamado através do pacote <code>{reticulate}</code> <span class="citation" data-cites="reticulate">(<a href="bibliografia.html#ref-reticulate" role="doc-biblioref">USHEY; ALLAIRE; TANG, 2022</a>)</span>. Além disso, a implementação das técnicas do oráculo envolviam modificações na função de perda, que são difíceis de implementar no ambiente do <code>{tensorflow}</code>, justamente por conta da necessidade de conhecer o código python que roda por trás dos códigos mais usuais.</p>
<p>Com o advento do pacote <code>{torch}</code><span class="citation" data-cites="torch-2">(<a href="bibliografia.html#ref-torch-2" role="doc-biblioref">FALBEL; LURASCHI, 2022</a>)</span>, no entanto, tudo foi facilitado. O pacote não possui dependências com o python, além de ser bastante transparente e flexível na construção da arquitetura do modelo, funções de perda e otimização. O pacote, também construído por Daniel Falbel, é um grande avanço científico e facilitou muito a construção dos códigos desta tese.</p>
<p>O pacote <code>{captcha}</code>, apesar de ter sido construído do zero, foi desenvolvido durante <em>lives</em> realizadas na plataforma <em>Twitch</em>. A construção em <em>lives</em> foi interessante porque era possível obter <em>feedback</em> e ideias da comunidade durante a construção da ferramenta, o que acelerou o desenvolvimento e auxiliou na arquitetura do pacote.</p>
<p>Com o desenvolvimento da tese, notou-se a necessidade de construir alguns pacotes adicionais. Os pacote <code>{captchaDownload}</code> e <code>{captchaOracle}</code> foram desenvolvidos para facilitar a obtenção dos resultados da tese, enquanto o pacote <code>{captcha}</code> pode ser utilizado por qualquer pessoa interessada em visualizar, classificar e resolver Captchas. As próximas subseções do apêndice descrevem os três pacotes.</p>
<section id="sec-pacote-captcha" class="level2">
<h2 class="anchored" data-anchor-id="sec-pacote-captcha">Pacote captcha</h2>
<p>O pacote <code>{captcha}</code> foi construído para funcionar como uma caixa de ferramentas para pessoas que desejam trabalhar com Captchas. O pacote possui funções de leitura, visualização, classificação, preparação de dados, modelagem, carregamento de modelos pré-treinados e predição. O pacote também permite a construção de um fluxo de trabalho para resolver um novo Captcha, criando um pacote para orquestrar o passo-a-passo.</p>
<section id="uso-básico" class="level3">
<h3 class="anchored" data-anchor-id="uso-básico">Uso básico</h3>
<p>A utilização básica do <code>{captcha}</code> envolve as funções <code>read_captcha()</code>, <code>plot()</code>, <code>captcha_annotate()</code>, <code>captcha_load_model()</code> e <code>decrypt()</code>. As funções são explicadas abaixo.</p>
<p>A função <code>read_captcha()</code> lê um vetor de arquivos de imagens e armazenar na memória. Por trás, a função utiliza o pacote <code>{magick}</code> para lidar com os tipos de arquivos que podem aparecer (JPEG, PNG, entre outros).</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(captcha)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>exemplo <span class="ot">&lt;-</span> <span class="st">"assets/img/dados_tjmg.jpeg"</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>captcha <span class="ot">&lt;-</span> <span class="fu">read_captcha</span>(exemplo)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>captcha</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   format width height colorspace matte filesize density</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1   JPEG   100     50       sRGB FALSE     4530   72x72</span></span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="pacote_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid"></p>
</div>
</div>
<p>A função retorna um objeto com a classe <code>captcha</code>, que pode ser utilizada por outros métodos.</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(captcha)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] "captcha"</span></span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>O objeto é uma lista com três elementos: <code>$img</code>, que contém imagem lida com o pacote <code>{magick}</code>, <code>$lab</code>, que contém o rótulo da imagem (por padrão, <code>NULL</code>) e <code>$path</code>, que contém o caminho da imagem que foi lida.</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(captcha)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Class 'captcha'  hidden list of 3</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ img :Class 'magick-image' &lt;externalptr&gt; </span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ lab : NULL</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ path: chr "assets/img/dados_tjmg.jpeg"</span></span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>A função <code>read_captcha()</code> possui um parâmetro <code>lab_in_path=</code>, que indica se o rótulo está contido no caminho da imagem. Se <code>lab_in_path=TRUE</code>, a função tentará extrair o rótulo do arquivo (obtendo o texto que vem depois do último <code>_</code> do caminho) e armazenar no elemento <code>$lab</code>.</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>exemplo <span class="ot">&lt;-</span> <span class="st">"assets/img/mnist128c49c36e13_6297.png"</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>captcha <span class="ot">&lt;-</span> <span class="fu">read_captcha</span>(exemplo, <span class="at">lab_in_path =</span> <span class="cn">TRUE</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(captcha)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Class 'captcha'  hidden list of 3</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ img :Class 'magick-image' &lt;externalptr&gt; </span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ lab : chr "6297"</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ path: chr "assets/img/mnist128c49c36e13_6297.png"</span></span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>A função plot <code>plot()</code> é um método de classe S3 do R básico. A função foi implementada para facilitar a visualização de Captchas. A função recebe uma lista de imagens obtida pela função <code>read_captcha()</code> e mostra o Captcha visualmente, como na <a href="#fig-exemplo-plot">Figura&nbsp;<span>A.1</span></a>.</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>exemplo <span class="ot">&lt;-</span> <span class="st">"assets/img/dados_tjmg.jpeg"</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>captcha <span class="ot">&lt;-</span> <span class="fu">read_captcha</span>(exemplo)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(captcha)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-exemplo-plot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="pacote_files/figure-html/fig-exemplo-plot-1.png" class="img-fluid figure-img" style="width:30.0%"></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;A.1: Exemplo de aplicação da função plot a um objeto <code>captcha</code>.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Um aspecto interessante da função <code>plot()</code> é que ela lida com uma lista de Captchas. Isso é útil quando o interesse é visualizar vários Captchas de uma vez na imagem. A <a href="#fig-exemplo-plot-multi">Figura&nbsp;<span>A.2</span></a> mostra um exemplo de aplicação</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>exemplos <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"assets/img/"</span>, <span class="fu">c</span>(</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">"dados_tjmg.jpeg"</span>,</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">"dados_esaj.png"</span>,</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">"dados_rfb.png"</span>,</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">"dados_sei.png"</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>))</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>captchas <span class="ot">&lt;-</span> <span class="fu">read_captcha</span>(exemplos)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(captchas)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-exemplo-plot-multi" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="pacote_files/figure-html/fig-exemplo-plot-multi-1.png" class="img-fluid figure-img" style="width:70.0%"></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;A.2: Exemplo de aplicação da função plot a um objeto <code>captcha</code> com várias imagens.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Por padrão, a função plot dispõe as imagens em quatro colunas. Para mudar o padrão, é possível modificar as opções usando <code>options(captcha.print.cols = N)</code>, onde <code>N</code> é o número de colunas desejado. A <a href="#fig-exemplo-plot-multi-2col">Figura&nbsp;<span>A.3</span></a> mostra um exemplo com duas colunas.</p>
<div class="cell">

</div>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">captcha.print.cols =</span> <span class="dv">2</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(captchas)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-exemplo-plot-multi-2col" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="pacote_files/figure-html/fig-exemplo-plot-multi-2col-1.png" class="img-fluid figure-img" style="width:60.0%"></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;A.3: Exemplo de aplicação da função plot a um objeto <code>captcha</code> com várias imagens, disponibilizadas em duas colunas.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell">

</div>
<p>Quando o vetor de Captchas é muito grande, a função <code>plot()</code> mostra um número máximo d imagens, acompanhado de uma mensagem. Por padrão, esse número é 100, com 25 linhas e 4 colunas. A opção pode ser sobrescrita combinando as opções <code>captcha.print.cols=</code> e <code>captcha.print.rows=</code>. A <a href="#fig-exemplo-plot-multi-varias">Figura&nbsp;<span>A.4</span></a> mostra um exemplo do comportamento da função quando o número de imagens excede 100.</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># mais de 100 imagens:</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>exemplos <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="st">"assets/img/dados_tjmg.jpeg"</span>, <span class="dv">110</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>captchas <span class="ot">&lt;-</span> <span class="fu">read_captcha</span>(exemplos)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(captchas)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ℹ Too many images, printing first 100. To override, run</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; • options('captcha.print.rows' = MAX_ROWS)</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; • options('captcha.print.cols' = COLUMNS)</span></span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-exemplo-plot-multi-varias" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="pacote_files/figure-html/fig-exemplo-plot-multi-varias-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;A.4: Demonstração da função <code>plot()</code> com muitas imagens.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Um detalhe interessante é que é possível criar subconjuntos de um objeto de classe <code>captcha</code> simplesmente utilizando o operador <code>[</code>. A função <code>length()</code> também pode ser utilizada para medir a quantidade de imagens lidas. A <a href="#fig-exemplo-plot-multi-varias-subset">Figura&nbsp;<span>A.5</span></a> mostra um exemplo dessas operações.</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>captchas_subset <span class="ot">&lt;-</span> captchas[<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>]</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(captchas_subset) <span class="co"># 20</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 20</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(captchas_subset)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-exemplo-plot-multi-varias-subset" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="pacote_files/figure-html/fig-exemplo-plot-multi-varias-subset-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;A.5: Demonstração das funções de subset e length aplicadas a um objeto do tipo <code>captcha</code>.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Por fim, se a imagem possui um rótulo, por padrão, a função <code>plot()</code> mostra o rótulo no canto da imagem. A <a href="#fig-exemplo-plot-rotulado">Figura&nbsp;<span>A.6</span></a> mostra um exemplo.</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>exemplo <span class="ot">&lt;-</span> <span class="st">"assets/img/mnist128c49c36e13_6297.png"</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>captcha <span class="ot">&lt;-</span> <span class="fu">read_captcha</span>(exemplo, <span class="at">lab_in_path =</span> <span class="cn">TRUE</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(captcha)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-exemplo-plot-rotulado" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="pacote_files/figure-html/fig-exemplo-plot-rotulado-1.png" class="img-fluid figure-img" style="width:30.0%"></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;A.6: Demonstração da função <code>plot()</code> quando o Captcha possui um rótulo</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>A função <code>captcha_annotate()</code> serve para classificar uma imagem de Captcha, manual ou automaticamente. Isso é feito modificando o caminho da imagem, adicionando o texto <code>_rotulo</code> ao final do caminho do arquivo. A função possui os parâmetros listados abaixo:</p>
<ul>
<li><code>files=</code>: objeto de classe <code>captcha</code> lido com a função <code>read_captcha()</code> (recomendado) ou vetor de caminhos de arquivos.</li>
<li><code>labels=</code>: (opcional) vetor com os rótulos das imagens. Deve ter o mesmo <code>length()</code> do que <code>files=</code>. Por padrão, o valor é <code>NULL</code>, indicando que deve ser aberto um <code>prompt</code> para que o usuário insira a resposta manualmente.</li>
<li><code>path=</code>: (opcional) caminho da pasta onde os arquivos classificados serão salvos. Por padrão, salva os arquivos com nomes modificados na mesma pasta dos arquivos originais.</li>
<li><code>rm_old=</code>: (opcional) deletar ou não os arquivos originais. Por padrão, é <code>FALSE</code>.</li>
</ul>
<p>A função, depois de aplicada, retorna um vetor com os caminhos dos arquivos modificados. O parâmetro <code>labels=</code> é útil para lidar com situações em que sabemos o rótulo do Captcha. Por exemplo, em um fluxo de trabalho que utiliza o oráculo, pode ser que um modelo inicial já forneça o valor correto do rótulo.</p>
<p>Quando não existe um rótulo, a função <code>captcha_annotate()</code>, que abre o <code>prompt</code> para classificação e aplica <code>plot()</code> para visualizar a imagem. A <a href="#fig-exemplo-classify">Figura&nbsp;<span>A.7</span></a> mostra um exemplo de aplicação da função <code>captcha_annotate()</code> no software <a href="https://posit.co/download/rstudio-desktop/">RStudio</a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-exemplo-classify" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="assets/img/exemplo_classify.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;A.7: Exemplo de aplicação da função classify. O rótulo <code>bhusp5</code> foi inserido manualmente.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Por último, a função <code>decrypt()</code> tem o papel de obter o rótulo de uma imagem utilizando um modelo já treinado para aquele tipo de imagem. A função recebe dois argumentos: <code>file=</code> que pode ser tanto o caminho do arquivo quanto um objeto de classe <code>captcha</code>, e um argumento <code>model=</code>, que contém um modelo de classe <code>luz_module_fitted</code>, ajustado utilizando as ferramentas que serão apresentadas na próxima subseção.</p>
<p>Para a tese, foram desenvolvidos modelos para vários Captchas diferentes. É possível carregar um modelo já treinado usando a função <code>captcha_load_model()</code>, podendo receber em seu único parâmetro <code>path=</code> o caminho de um arquivo contendo um modelo ajustado ou uma <em>string</em> com o nome de um modelo já treinado, como <code>"rfb"</code>, por exemplo. Os modelos treinados são armazenados nos <a href="https://github.com/decryptr/captcha/releases">releases do repositório do pacote captcha</a>, são baixados e controlados pelo pacote <code>{piggyback}</code> <span class="citation" data-cites="piggyback">(<a href="bibliografia.html#ref-piggyback" role="doc-biblioref">BOETTIGER; HO, 2022</a>)</span> e são lidos utilizando o pacote <code>{luz}</code>, que será descrito em maiores detalhes na próxima subseção. No momento de submissão da tese, os Captchas com modelos desenvolvidos eram <code>trf5</code>, <code>tjmg</code>, <code>trt</code>, <code>esaj</code>, <code>jucesp</code>, <code>tjpe</code>, <code>tjrs</code>, <code>cadesp</code>, <code>sei</code> e <code>rfb</code>.</p>
<p>A <a href="#fig-diagrama-captcha-simples">Figura&nbsp;<span>A.8</span></a> resume visualmente as funções apresentadas até o momento. As setas indicam a dependência das funções de objetos gerados por outras funções.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-diagrama-captcha-simples" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
</p><pre class="mermaid mermaid-js" data-tooltip-selector="#mermaid-tooltip-1">flowchart LR
  B("&lt;b&gt;&lt;span style='color:blue;'&gt;captcha&lt;/span&gt;&lt;/b&gt; &lt;- &lt;b&gt;read_captcha&lt;/b&gt;('path/to/file.png')")
  B --&gt; C("&lt;b&gt;plot&lt;/b&gt;(&lt;b&gt;&lt;span style='color:blue;'&gt;captcha&lt;/span&gt;&lt;/b&gt;)")
  B --&gt; D("&lt;b&gt;captcha_annotate&lt;/b&gt;(&lt;b&gt;&lt;span style='color:blue;'&gt;captcha&lt;/span&gt;&lt;/b&gt;)")
  B --&gt; F("&lt;b&gt;decrypt&lt;/b&gt;(&lt;b&gt;&lt;span style='color:blue;'&gt;captcha&lt;/span&gt;&lt;/b&gt;, &lt;b&gt;&lt;span style='color:green;'&gt;model&lt;/span&gt;&lt;/b&gt;)")  
  G("&lt;b&gt;&lt;span style='color:green;'&gt;model&lt;/span&gt;&lt;/b&gt; &lt;- &lt;b&gt;captcha_load_model&lt;/b&gt;('model_name')") --&gt; F
style B fill:#d3ddf1,stroke:#333,stroke-width:2px
</pre>
<div id="mermaid-tooltip-1" class="mermaidTooltip">

</div>
<p></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;A.8: Diagrama das funções básicas do pacote <code>{captcha}</code></figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="sec-ap-modelagem" class="level3">
<h3 class="anchored" data-anchor-id="sec-ap-modelagem">Modelagem</h3>
<p>O pacote <code>{captcha}</code> também fornece uma interface básica para o desenvolvimento de modelos a partir de uma base completamente classificada. A classificação pode ser feita manualmente pela função <code>captcha_annotate()</code>, apresentada anteriormente, ou por outro método desenvolvido pelo usuário.</p>
<p>A parte de modelagem parte de algumas premissas sobre a base de dados. As imagens precisam estar em uma pasta e ter o padrão <code>caminho/do/arquivo/&lt;id&gt;_&lt;lab&gt;.&lt;ext&gt;</code>, onde:</p>
<ul>
<li><code>&lt;id&gt;</code>: pode ser qualquer nome, de preferência sem acentuação ou outros caracteres especiais, para evitar problemas de <em>encoding</em>. Geralmente, é um <em>hash</em> identificando o tipo e id do captcha. <strong>Observação</strong>: ao classificar um caso, é importante que o <code>id</code> seja único, já que dois Captchas podem ter o mesmo rótulo.</li>
<li><code>&lt;lab&gt;</code>: é o rótulo do Captcha. Pode ser um conjunto de caracteres entre <code>[a-zA-Z0-9]</code>, diferenciando maiúsculas e minúsculas se necessário. No momento, todos os arquivos em uma pasta devem ter a mesma quantidade de caracteres (comprimento homogêneo). Futuramente, o pacote poderá considerar Captchas de comprimento heterogêneo.</li>
<li><code>&lt;ext&gt;</code>: extensão do arquivo. Pode ser <code>.png</code>, <code>.jpeg</code> ou <code>.jpg</code>. As operações também funcionam para o formato <code>.svg</code>, mas pode apresentar problemas por conta da transparência da imagem.</li>
</ul>
<p>Atendidas as premissas da base classificada, é possível ajustar um modelo de redes neurais usando o pacote <code>{captcha}</code>. No entanto, como o ajuste de modelos de redes neurais envolve uma série de nuances e pequenas adaptações, optou-se por exportar funções em dois níveis de aprofundamento. A primeira é a <strong>automatizada</strong>, utilizando a função <code>captcha_fit_model()</code> descrito a seguir, enquanto a segunda é a <strong>procedimental</strong>, utilizando o passo a passo descrito na Subseção <a href="#sec-captcha-do-zero"><span>A.1.3</span></a>.</p>
<p>A função <code>captcha_fit_model()</code> ajusta um modelo a partir de uma pasta com arquivos classificados. A função recebe os parâmetros: <code>dir=</code>, contendo o caminho dos arquivos classificados; <code>dir_valid=</code>, (opcional) contendo o caminho dos arquivos classificados para validação; <code>prop_valid=</code>, contendo a proporção da base de treino a ser considerada como validação, ignorada quando <code>dir_valid=</code> é fornecida (por padrão, considera-se 20% da base para validação).</p>
<p>A função <code>captcha_fit_model()</code> também possui alguns parâmetros relacionados à modelagem. São eles: <code>dropout=</code>, especificando o percentual de <em>dropout</em> aplicado às camadas ocultas da rede (por padrão, <code>0.25</code>); <code>dense_units=</code>, especificando a quantidade de unidades na camada oculta que vem depois das camadas convolucionais (por padrão, 200); <code>decay=</code>, especificando o percentual de decaimento da taxa de aprendizado (por padrão, <code>0.99</code>); <code>epochs=</code> número de épocas para ajuste do modelo (por padrão 100). Uma observação importante é que o modelo está configurado para parar o ajuste após 20 iterações sem redução significativa na função de perda (arbitrado em 1%; para mais detalhes ver a Subseção <a href="#sec-captcha-do-zero"><span>A.1.3</span></a>).</p>
<p>No final, a função retorna um modelo ajustado com classe <code>luz_module_fitted</code>, que pode ser salvo em disco utilizando-se a função <code>luz_save()</code>. O modelo também pode ser serializado para utilização em outros pacotes como pytorch. Um tutorial sobre serialização pode ser encontrado na <a href="https://torch.mlverse.org/docs/articles/serialization.html">documentação do pacote torch</a>.</p>
<p>O pacote <code>{captchaOracle}</code> possui uma interface similar para trabalhar com bases parcialmente classificadas. Como a estrutura de dados nesse caso é mais complexa e pode evoluir no futuro, os códigos foram organizados em outro pacote. Mais detalhes na Seção <a href="#sec-pacote-oracle"><span>A.3</span></a>.</p>
<p>Na documentação do pacote <code>{captcha}</code>, foi adicionado um exemplo de aplicação. O exemplo utiliza captchas gerados usando a função <code>captcha_generate()</code>, que gera Captchas utilizando o pacote <code>{magick}</code>. O Captcha foi criado para a construção da tese, apelidado de <code>R-Captcha</code>, e possui os seguintes parâmetros:</p>
<ul>
<li><code>write_disk=</code>: salvar os arquivos em disco? Por padrão, é falso.</li>
<li><code>path=</code>: Caminho para salvar arquivos em disco, caso o parâmetro anterior seja verdadeiro.</li>
<li><code>chars=</code>: Quais caracteres usar na imagem.</li>
<li><code>n_chars=</code>: O comprimento do Captcha.</li>
<li><code>n_rows=</code>: Altura da imagem, em pixels.</li>
<li><code>n_cols=</code>: Largura da imagem, em pixels.</li>
<li><code>p_rotate=</code>: Probabilidade de rotação da imagem.</li>
<li><code>p_line=</code>: Probabilidade de adicionar um risco entre as letras.</li>
<li><code>p_stroke=</code>: Probabilidade de adicionar uma borda nas letras.</li>
<li><code>p_box=</code>: Probabilidade de adicionar uma caixa (retângulo) em torno das letras.</li>
<li><code>p_implode=</code>: Probabilidade de adicionar efeitos de implosão.</li>
<li><code>p_oilpaint=</code>: Probabilidade de adicionar efeitos de tinta a óleo.</li>
<li><code>p_noise=</code>: Probabilidade de adicionar um ruído branco no fundo da imagem.</li>
<li><code>p_lat=</code>: Probabilidade de aplicar o algoritmo <em>local adaptive thresholding</em> à imagem.</li>
</ul>
</section>
<section id="sec-captcha-do-zero" class="level3">
<h3 class="anchored" data-anchor-id="sec-captcha-do-zero">Resolvendo um novo Captcha do zero</h3>
<p>Em algumas situações, pode ser desejável rodar modelos de forma customizada. Isso acontece pois modelos de aprendizagem profunda costumam precisar de diversos pequenos ajustes, como a taxa de aprendizado, utilização de outras funções de otimização, camadas computacionais e funções de pré-processamento.</p>
<p>A função <code>captcha_fit_model()</code>, apresentada na subseção anterior, é engessada. Ela aceita alguns parâmetros para estruturar o modelo, mas não possui elementos suficientes para customização. É para isso que pacotes como <code>{torch}</code> e <code>{luz}</code> existem, pois criam ambientes de computação mais flexíveis para operar os modelos de aprendizado profundo.</p>
<p>Outra desvantagem da utilização do <code>captcha_fit_model()</code> é a disponibilização dos modelos. Um modelo pode ser utilizado localmente, mas a tarefa de disponibilizar as bases de dados e o modelo para outras pessoas não tem um procedimento bem definido.</p>
<p>Para organizar o fluxo de trabalho, implementou-se um fluxo de classificação de Captchas dentro do pacote <code>{captcha}</code>. A função que orquestra esse fluxo é a <code>new_captcha()</code>. A função possui apenas um parâmetro, <code>path=</code>, que é o caminho de uma nova pasta a ser criada.</p>
<p>A função também pode ser chamada criando-se um projeto dentro do próprio RStudio. A <a href="#fig-exemplo-rstudio-template">Figura&nbsp;<span>A.9</span></a> mostra um exemplo de utilização do template dentro do RStudio, após clicar em <code>Novo Projeto &gt; Novo Diretório</code>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-exemplo-rstudio-template" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="assets/img/exemplo-rstudio-template.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;A.9: Exemplo de criação de um novo projeto de Captcha utilizando o RStudio.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Ao criar um novo projeto, pelo comando <code>new_captcha()</code> ou pela interface do RStudio, uma nova janela é aberta. O projeto contém quatro arquivos:</p>
<ul>
<li><code>01_download.R</code>: Contém algumas funções para auxiliar no desenvolvimento de funções que baixam Captchas em um caso real. Na prática, as funções que baixam Captchas precisam ser adaptadas porque os sites são organizados de formas muito diferentes.</li>
<li><code>02_annotate.R</code>: Contém um <em>template</em> para classificação manual de Captchas. A classificação manual pode tanto ser realizada usando a interface criada pelo pacote <code>{captcha}</code> quanto externamente. No final, os arquivos classificados devem ser salvos na pasta <code>img</code>, no formato descrito na Subseção <a href="#sec-ap-modelagem"><span>A.1.2</span></a>.</li>
<li><code>03_model.R</code>: Contém um <em>template</em> para modelagem, permitindo a customização completa do procedimento de ajuste. O <em>script</em> contém comandos para carregar os dados, especificar o modelo, realizar o ajuste e salvar o modelo ajustado.</li>
<li><code>04_share.R</code>: Contém funções para criar um repositório <em>git</em> da solução e disponibilizar o modelo ajustado. O modelo poderá ser lido e aplicado utilizando-se a função <code>captcha_load_model()</code>, para utilização em diferentes contextos, sem a necessidade de copiar arquivos localmente.</li>
</ul>
<p>Sobre a parte de modelagem, cabe uma descrição mais detalhada. O primeiro passo do <em>script</em> é criar objetos do tipo <em>dataset</em> (objeto que armazena os dados de forma consistente) e <em>dataloader</em> (objeto que obtém amostras do dataset, que são utilizadas como os <em>minibatches</em> do modelo), com uma estrutura orquestrada pelo pacote <code>{torch}</code>.</p>
<p>A função <code>captcha_dataset()</code> cria o <em>dataset</em> recebendo como parâmetro uma pasta de arquivos e gera um objeto com classes <code>my_captcha</code>, <code>dataset</code> e <code>R6</code>. A função é, na verdade, um objeto do tipo <code>dataset_generator</code>, criada utilizando-se a função <code>dataset()</code> do pacote <code>{torch}</code>. O objeto é chamado da mesma forma que uma função usual do R, aceitando alguns parâmetros adicionais:</p>
<ul>
<li><code>transform_image=</code>: operação de transformação a ser aplicada à imagem. Por padrão, utiliza a função <code>captcha_transform_image()</code>, que lê a imagem e redimensiona para ficar com dimensões <code>32x192</code>. A dimensão foi escolhida para facilitar a implementação das camadas convolucionais e para lidar com o fato de que usualmente os Captchas são imagens retangulares.</li>
<li><code>transform_label=</code>: operação de transformação para gerar a variável resposta. Por padrão, utiliza a função <code>captcha_transform_label()</code>, que recebe um vetor de todos os possíveis caracteres do Captcha e aplica a operação <code>one_hot()</code>, obtendo-se a versão matricial da resposta com zeros e uns, como descrito na <a href="metodologia.html#sec-definicao-captcha"><span>Seção&nbsp;2.1.1</span></a>.</li>
<li><code>augmentation=</code>: operações para aumentação de dados . Por exemplo, pode ser uma função que adiciona um ruído aleatório à imagem original para que, ao gerar uma nova amostra, os dados utilizados sejam sempre diferentes.</li>
</ul>
<p>A função <code>captcha_dataset()</code> deve ser aplicada duas vezes, uma para criar a base de treino e outra para criar a base de validação. A separação de bases de treino e validação deve ser feita de forma manual, copiando parte dos Captchas classificados para uma nova pasta, com aleatorização. É papel do usuário separar as bases em pastas distintas carregá-as em um <em>dataset</em>.</p>
<p>Em seguida, os <em>dataloaders</em> são criados utilizando-se a função <code>dataloader()</code> do pacote <code>{torch}</code>. Nessa parte é definido o tamanho do <em>minibatch</em>, além de outros possíveis parâmetros disponíveis na função do <code>{torch}</code>. Para mais detalhes, o usuário pode <a href="https://torch.mlverse.org/docs/reference/dataloader.html">acessar a documentação da função neste link</a>. Devem ser criados <em>dataloaders</em> tanto para a base de treino quanto para a base de validação.</p>
<p>A próxima etapa é a especificação do modelo. No <em>script</em> de modelagem, o modelo é fornecido pelo objeto <code>net_captcha</code> do pacote <code>{captcha}</code>. Assim como no caso do <em>dataset</em>, o <code>net_captcha</code> é um objeto especial do <code>{torch}</code>, com classes <code>CAPTCHA-CNN</code>, <code>nn_module</code> e <code>nn_module_generator</code>, O objeto pode ser utilizado como uma função, gerando um módulo do <code>torch</code>, similar a uma função de predição. No entanto, por conta da forma que o objeto é utilizado em passos posteriores pelo pacote <code>{luz}</code>, o objeto a ser considerado é mesmo o <code>nn_module_generator</code>, como colocado no <em>script</em>.</p>
<p>Para customizar o modelo, o usuário deve modificar os métodos <code>initialize()</code> e <code>forward()</code>, acessados dentro do objeto <code>net_captcha$public_methods</code>. O primeiro é responsável pela inicialização do modelo, contendo a descrição das operações que são realizadas, como convoluções. O segundo é a função <em>feed forward</em> das redes neurais, que recebe uma imagem e retorna um objeto contendo os <em>logitos</em> ou probabilidades, no formato da variável resposta.</p>
<p>Por padrão, o código de inicialização do modelo é o descrito abaixo. Os parâmetros <code>input_dim=</code>, <code>output_ndigits=</code>, <code>output_vocab_size=</code> e <code>vocab=</code> descrevem, respectivamente, as dimensões da imagem, o comprimeiro da resposta, o comprimento do alfabeto e os elementos do alfabeto. Os parâmetros <code>transform=</code>, <code>dropout=</code> e <code>dense_units=</code> controlam, respectivamente, a função de transformação da imagem, os hiperparâmetros de <em>dropout</em> e a quantidade de unidades na camada densa. É possível notar que os parâmetros das convoluções são fixos, já preparados para funcionar bem com uma imagem de dimensões <code>32x192</code>.</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>initialize <span class="ot">=</span> <span class="cf">function</span>(input_dim,</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>                      output_ndigits,</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>                      output_vocab_size,</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>                      vocab,</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>                      transform,</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>                      <span class="at">dropout =</span> <span class="fu">c</span>(.<span class="dv">25</span>, .<span class="dv">25</span>),</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>                      <span class="at">dense_units =</span> <span class="dv">400</span>) {</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># in_channels, out_channels, kernel_size, stride = 1, padding = 0</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>  self<span class="sc">$</span>batchnorm0 <span class="ot">&lt;-</span> torch<span class="sc">::</span><span class="fu">nn_batch_norm2d</span>(<span class="dv">3</span>)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>  self<span class="sc">$</span>conv1 <span class="ot">&lt;-</span> torch<span class="sc">::</span><span class="fu">nn_conv2d</span>(<span class="dv">3</span>, <span class="dv">32</span>, <span class="dv">3</span>)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>  self<span class="sc">$</span>batchnorm1 <span class="ot">&lt;-</span> torch<span class="sc">::</span><span class="fu">nn_batch_norm2d</span>(<span class="dv">32</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>  self<span class="sc">$</span>conv2 <span class="ot">&lt;-</span> torch<span class="sc">::</span><span class="fu">nn_conv2d</span>(<span class="dv">32</span>, <span class="dv">64</span>, <span class="dv">3</span>)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>  self<span class="sc">$</span>batchnorm2 <span class="ot">&lt;-</span> torch<span class="sc">::</span><span class="fu">nn_batch_norm2d</span>(<span class="dv">64</span>)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>  self<span class="sc">$</span>conv3 <span class="ot">&lt;-</span> torch<span class="sc">::</span><span class="fu">nn_conv2d</span>(<span class="dv">64</span>, <span class="dv">64</span>, <span class="dv">3</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>  self<span class="sc">$</span>batchnorm3 <span class="ot">&lt;-</span> torch<span class="sc">::</span><span class="fu">nn_batch_norm2d</span>(<span class="dv">64</span>)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>  self<span class="sc">$</span>dropout1 <span class="ot">&lt;-</span> torch<span class="sc">::</span><span class="fu">nn_dropout2d</span>(dropout[<span class="dv">1</span>])</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>  self<span class="sc">$</span>dropout2 <span class="ot">&lt;-</span> torch<span class="sc">::</span><span class="fu">nn_dropout2d</span>(dropout[<span class="dv">2</span>])</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>  self<span class="sc">$</span>fc1 <span class="ot">&lt;-</span> torch<span class="sc">::</span><span class="fu">nn_linear</span>(</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># must be the same as last convnet</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">in_features =</span> <span class="fu">prod</span>(<span class="fu">calc_dim_conv</span>(input_dim)) <span class="sc">*</span> <span class="dv">64</span>,</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">out_features =</span> dense_units</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>  self<span class="sc">$</span>batchnorm_dense <span class="ot">&lt;-</span> torch<span class="sc">::</span><span class="fu">nn_batch_norm1d</span>(dense_units)</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>  self<span class="sc">$</span>fc2 <span class="ot">&lt;-</span> torch<span class="sc">::</span><span class="fu">nn_linear</span>(</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">in_features =</span> dense_units,</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">out_features =</span> output_vocab_size <span class="sc">*</span> output_ndigits</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>  self<span class="sc">$</span>output_vocab_size <span class="ot">&lt;-</span> output_vocab_size</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>  self<span class="sc">$</span>input_dim <span class="ot">&lt;-</span> input_dim</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>  self<span class="sc">$</span>output_ndigits <span class="ot">&lt;-</span> output_ndigits</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>  self<span class="sc">$</span>vocab <span class="ot">&lt;-</span> vocab</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>  self<span class="sc">$</span>transform <span class="ot">&lt;-</span> transform</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>A função de <em>feed forward</em> foi descrita abaixo. A função aplica o passo-a-passo descrito na <a href="metodologia.html#sec-arquitetura-rede"><span>Seção&nbsp;2.1.2.1</span></a>, recebendo uma imagem <code>x</code> como entrada e retornando uma matriz de logitos, que dão os pesos do modelo para cada letra da resposta. O modelo retorna os logitos e não as probabilidades porque, no passo seguinte, a função de perda considera como entrada os logitos. Se o usuário decidir modificar o método <code>forward</code> para retornar probabilidades, precisará também adaptar a função de perda utilizada.</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>forward <span class="ot">=</span> <span class="cf">function</span>(x) {</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  out <span class="ot">&lt;-</span> x <span class="sc">|&gt;</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># normalize</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">batchnorm0</span>() <span class="sc">|&gt;</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># layer 1</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">conv1</span>() <span class="sc">|&gt;</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    torch<span class="sc">::</span><span class="fu">nnf_relu</span>() <span class="sc">|&gt;</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    torch<span class="sc">::</span><span class="fu">nnf_max_pool2d</span>(<span class="dv">2</span>) <span class="sc">|&gt;</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">batchnorm1</span>() <span class="sc">|&gt;</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># layer 2</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">conv2</span>() <span class="sc">|&gt;</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    torch<span class="sc">::</span><span class="fu">nnf_relu</span>() <span class="sc">|&gt;</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    torch<span class="sc">::</span><span class="fu">nnf_max_pool2d</span>(<span class="dv">2</span>) <span class="sc">|&gt;</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">batchnorm2</span>() <span class="sc">|&gt;</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># layer 3</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">conv3</span>() <span class="sc">|&gt;</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>    torch<span class="sc">::</span><span class="fu">nnf_relu</span>() <span class="sc">|&gt;</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>    torch<span class="sc">::</span><span class="fu">nnf_max_pool2d</span>(<span class="dv">2</span>) <span class="sc">|&gt;</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">batchnorm3</span>() <span class="sc">|&gt;</span></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># dense</span></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>    torch<span class="sc">::</span><span class="fu">torch_flatten</span>(<span class="at">start_dim =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">dropout1</span>() <span class="sc">|&gt;</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">fc1</span>() <span class="sc">|&gt;</span></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>    torch<span class="sc">::</span><span class="fu">nnf_relu</span>() <span class="sc">|&gt;</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">batchnorm_dense</span>() <span class="sc">|&gt;</span></span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">dropout2</span>() <span class="sc">|&gt;</span></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">fc2</span>()</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>  out<span class="sc">$</span><span class="fu">view</span>(<span class="fu">c</span>(</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>    <span class="fu">dim</span>(out)[<span class="dv">1</span>],</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>output_ndigits,</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>output_vocab_size</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>  ))</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Definida a arquitetura do modelo, o penúltimo passo é o ajuste. O ajuste do modelo é orquestrado pelo pacote <code>{luz}</code>, que facilita a criação do <em>loop</em> de ajuste dos parâmetros, desempenhando um papel similar ao que o <code>keras</code> realiza para o <code>tensorflow</code> puro.</p>
<p>No caso dos Captchas, o código <code>{luz}</code> para ajuste do modelo segue quatro passos, encadeados pelo operador <em>pipe</em>, ou <code>|&gt;</code>:</p>
<ul>
<li><code>setup()</code>: serve para determinar a função de perda, o otimizador e as métricas a serem acompanhadas. No <em>script</em>, a função de perda utilizada é a <code>nn_multilabel_soft_margin_loss()</code> do <code>{torch}</code>, o otimizador é o <code>optim_adam()</code> do <code>{torch}</code> e a métrica é a <code>captcha_accuracy()</code>, desenvolvida no pacote <code>{captcha}</code> para apresentar a acurácia considerando a imagem completa do Captcha e não a acurácia de cada letra da imagem, que seria o resultado se fosse utilizada a função <code>luz_metric_accuracy()</code>, do pacote <code>{luz}</code>.</li>
<li><code>set_hparams()</code>: serve para informar os hiperparâmetros e outras informações do modelo. Os parâmetros colocados dentro dessa função são exatamente os parâmetros do método <code>initialize()</code> da rede neural criada no passo anterior.</li>
<li><code>set_opt_hparams()</code>: serve para informar os hiperparâmetros da otimização. Os parâmetros colocados nessa função são passados para a função de otimização. No script, o único parâmetro informado é a taxa de aprendizado, fixada em <code>0.01</code>.</li>
<li><code>fit()</code>: serve para inicializar o <em>loop</em> de ajuste do modelo. Aqui, é necessário passar os <em>dataloaders</em> de treino e validação, a quantidade de épocas (fixada em 100), e os <em>callbacks</em>, que são operações a serem aplicadas em diferentes momentos do ajuste (por exemplo, ao final de cada iteração). Por padrão, os <em>callbacks</em> são:
<ul>
<li>O decaimento da taxa de aprendizado utilizando uma taxa multiplicativa. A cada iteração, a taxa de aprendizado decai em um fator determinado pela função definida em <code>lr_lambda</code>, que por padrão é <code>0.99</code>. Ou seja, em cada época, a taxa de aprendizado fica 1% menor.</li>
<li>A parada precoce, ou <em>early stopping</em>. Por padrão, está configurado para parar o ajuste do modelo se forem passadas 20 épocas sem que o modelo melhore a acurácia em 1% na base de validação. Por exemplo, se em 20 épocas consecutivas o modelo permanecer com acurácia em 53%, o ajuste será encerrado, mesmo que não tenha passado pelas 100 épocas.</li>
<li>O arquivo de <code>log</code>. Por padrão, o modelo guarda o histórico de ajuste em um arquivo do tipo <em>comma separated values</em> (CSV), contendo a perda e a acurácia do modelo na base de treino e na base de validação, ao final de cada época. O arquivo de <code>log</code> é importante para acompanhar o ajuste do modelo e verificar sua performance ao longo das épocas, podendo dar <em>insights</em> sobre possíveis ajustes nos hiperparâmetros.</li>
</ul></li>
</ul>
<p>No final do fluxo definido pelo pacote <code>{luz}</code>, será obtido um modelo ajustado. O modelo possui a classe <code>luz_module_fitted</code> e pode ser investigado ao rodar o objeto no console do R. No exemplo do <code>R-Captcha</code> apresentado na subseção anterior, o objeto possui as características abaixo. O objeto contém um relatório conciso e bastante informativo, mostrando o tempo de ajuste, as métricas obtidas no treino e na validação e a arquitetura do modelo ajustado.</p>
<pre><code>A `luz_module_fitted`
── Time ────────────────────────────────────────────────
• Total time: 10m 48.1s
• Avg time per training batch: 415ms
• Avg time per validation batch 217ms

── Results ─────────────────────────────────────────────
Metrics observed in the last epoch.

ℹ Training:
loss: 0.0049
captcha acc: 0.996
ℹ Validation:
loss: 0.0356
captcha acc: 0.905

── Model ───────────────────────────────────────────────
An `nn_module` containing 628,486 parameters.

── Modules ─────────────────────────────────────────────
• batchnorm0: &lt;nn_batch_norm2d&gt; #6 parameters
• conv1: &lt;nn_conv2d&gt; #896 parameters
• batchnorm1: &lt;nn_batch_norm2d&gt; #64 parameters
• conv2: &lt;nn_conv2d&gt; #18,496 parameters
• batchnorm2: &lt;nn_batch_norm2d&gt; #128 parameters
• conv3: &lt;nn_conv2d&gt; #36,928 parameters
• batchnorm3: &lt;nn_batch_norm2d&gt; #128 parameters
• dropout1: &lt;nn_dropout&gt; #0 parameters
• dropout2: &lt;nn_dropout&gt; #0 parameters
• fc1: &lt;nn_linear&gt; #563,400 parameters
• batchnorm_dense: &lt;nn_batch_norm1d&gt; #400 parameters
• fc2: &lt;nn_linear&gt; #8,040 parameters</code></pre>
<p>Por último, o modelo deve ser salvo em um arquivo local. Isso é feito utilizando-se a função <code>luz_save()</code> do pacote <code>{luz}</code>, guardando um objeto com extensão <code>.pt</code>, que será disponibilizado no <code>04_share.R</code>.</p>
<p>Cabe também um detalhamento do <em>script</em> disponibilizado em <code>04_share.R</code>. O script utiliza o pacote <code>{usethis}</code> <span class="citation" data-cites="usethis">(<a href="bibliografia.html#ref-usethis" role="doc-biblioref">WICKHAM; BRYAN; BARRETT, 2022</a>)</span> para organizar o repositório, configurando o Git (software de versionamento de códigos) e o GitHub (sistema <em>web</em> de organização de repositórios). Além disso, o <em>script</em> utiliza o pacote <code>{piggyback}</code> <span class="citation" data-cites="piggyback">(<a href="bibliografia.html#ref-piggyback" role="doc-biblioref">BOETTIGER; HO, 2022</a>)</span> para disponibilizar o modelo ajustado nos <em>releases</em> do repositório criado. Opcionalmente, o usuário poderá também disponibilizar a base com os arquivos classificados em um arquivo <code>.zip</code>, o que é recomendado, pois permite que outras pessoas possam trabalhar com os mesmos dados e aprimorar os modelos.</p>
<p>Um detalhe importante é sobre a inserção de arquivos pesados no repositório. O <em>script</em> utiliza <em>releases</em> para disponibilizar as soluções porque não é uma boa prática subir arquivos como modelos ajustados ou arquivos brutos (imagens) diretamente no repositório. Isso acontece porque o repositório pode ficar demasiadamente pesado e o histórico do <em>Git</em> fica alterado.</p>
<p>Uma vez compartilhado nos releases do repositório, o modelo poderá ser lido por qualquer pessoa, em outras máquinas utilizando o pacote <code>{captcha}</code>. Basta rodar o código abaixo e o modelo será carregado.</p>
<div class="cell">

</div>
<p>Com isso, o trabalho pode ser compartilhado e Captchas podem ser resolvidos de forma colaborativa pelas pessoas interessadas. Utilizando o fluxo do <code>new_captcha()</code>, as pessoas têm flexibilidade para construir modelos customizados e utilizá-los de forma eficiente.</p>
</section>
</section>
<section id="sec-pacote-download" class="level2">
<h2 class="anchored" data-anchor-id="sec-pacote-download">Pacote captchaDownload</h2>
<p>O pacote <code>{captchaDownload}</code> foi construído para armazenar os códigos de baixar dados de Captchas de forma consistente. O pacote também inclui funções para trabalhar com oráculos.</p>
<p>O pacote não foi criado para ser usado por muitas pessoas. O intuito de criar o pacote foi o de organizar as funções utilizadas para realizar as simulações e obter os resultados empíricos da tese.</p>
<p>As funções do pacote <code>{captchaDownload}</code> são organizadas em dois tipos principais. As funções de <em>acesso</em>, identificadas pelo termo <code>_access</code>, fazem o <em>download</em> da imagem do Captcha e retornam todas as informações necessárias para fazer a verificação do oráculo, como, por exemplo, <em>cookies</em> e dados da sessão do usuário. Já as funções de <em>teste</em>, identificadas pelo termo <code>_test</code>, servem para verificar se um rótulo fornecido para o Captcha está correto ou não.</p>
<p>As funções ficam mais claras através de um exemplo. No caso do TRF5, por exemplo, o acesso é feito pela página do <a href="https://pje.trf5.jus.br/pjeconsulta/ConsultaPublica/listView.seam">sistema PJe</a>. A função <code>captcha_access_trf5()</code> recebe o parâmetro <code>path=</code>, que é a pasta para salvar a imagem, retornando uma lista com o caminho da imagem que foi salva e de componentes da sessão do usuário.</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>acesso <span class="ot">&lt;-</span> captchaDownload<span class="sc">:::</span><span class="fu">captcha_access_trf5</span>(<span class="st">"assets/img"</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>acesso</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<pre><code>$f_captcha
assets/img/trf5ac031dafbd.jpeg

$j_id
[1] "j_id1"

$u
[1] "https://pje.trf5.jus.br/pjeconsulta/ConsultaPublica/listView.seam"</code></pre>
<div class="cell">

</div>
<p>Em seguida, obtém-se o rótulo do modelo. Isso pode ser feito manualmente ou através de um modelo.</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magrittr) <span class="co"># </span><span class="al">TODO</span><span class="co"> remove</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>captcha <span class="ot">&lt;-</span> <span class="fu">read_captcha</span>(acesso<span class="sc">$</span>f_captcha)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(captcha)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>modelo_trf5 <span class="ot">&lt;-</span> <span class="fu">captcha_load_model</span>(<span class="st">"trf5"</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>(lab <span class="ot">&lt;-</span> <span class="fu">decrypt</span>(acesso<span class="sc">$</span>f_captcha, modelo_trf5))</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] "969588"</span></span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-exemplo-acesso-trf5" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="pacote_files/figure-html/fig-exemplo-acesso-trf5-1.png" class="img-fluid figure-img" style="width:20.0%"></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;A.10: Exemplo de Captcha baixado diretamente do TRF5.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Agora, aplica-se a função <code>captcha_test_trf5()</code> para verificar se o rótulo está correto ou incorreto. A verificação é feita de forma automática, diretamente da <em>internet</em>, através do oráculo. A função recebe dois parâmetros: <code>obj=</code> com as informações obtidas da função de acesso; e <code>label=</code>, o rótulo obtido. A função retorna <code>TRUE</code> se o rótulo está correto e <code>FALSE</code> caso contrário.</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>(acertou <span class="ot">&lt;-</span> captchaDownload<span class="sc">:::</span><span class="fu">captcha_test_trf5</span>(acesso, lab))</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<pre><code>[1] TRUE</code></pre>
<p>Cada Captcha possui uma função de acesso e uma função de teste. Na prática, se uma pessoa desejar resolver um novo Captcha usando a técnica do oráculo, são essas funções que ela precisar desenvolver. Todas as outras operações podem ser generalizadas para diferentes casos de uso e estão implementadas nos pacotes <code>{captchaDownload}</code> e <code>{captchaOracle}</code>. Vale notar que a construção dessas funções geralmente é necessária para a construção de <em>web scrapers</em>, ou seja, elas não criam dificuldades adicionais para pessoas interessadas em resolver Captchas para acessar dados da <em>internet</em>.</p>
<p>A função principal do pacote <code>{captchaDownload}</code> é a <code>captcha_oracle()</code>. A função é responsável por realizar a classificação parcial automática dos Captchas utilizando um modelo inicial e o oráculo. A função possui os seguintes parâmetros:</p>
<ul>
<li><code>path=</code>: caminho em que os arquivos serão salvos.</li>
<li><code>model=</code>: modelo para predizer o rótulo de uma imagem.</li>
<li><code>max_ntry=</code>: quantidade máxima de chutes até desistir.</li>
<li><code>manual=</code>: caso o máximo de tentativas seja alcançado, abrir o <em>prompt</em> para classificar manualmente? Por padrão, sim.</li>
<li><code>captcha_access=</code>: função que baixa um Captcha e retorna dados da sessão para validar o Captcha, como mostrada anteriormente.</li>
<li><code>captcha_test=</code>: função que testa se um Captcha está correto a partir de um rótulo específico, como mostrado anteriormente.</li>
</ul>
<p>A função amarra todos os conceitos necessários para criar novas bases de dados de forma automática. Primeiro, considera o caminho para salvar os dados. Em seguida, considera o modelo e formas de lidar com o oráculo. Por último, recebe as funções de acesso e de teste do Captcha. A função escreve um arquivo de <em>log</em> com os resultados dos testes. O arquivo contém <code>max_ntry</code> linhas, podendo ter uma linha adicional se <code>manual=TRUE</code>, já que, se o modelo errar todas os chutes, a classificação manual deve ser adicionada.</p>
<p>No exemplo do TRF5, a chamada da função <code>captcha_oracle()</code> com um chute ficaria da seguinte forma:</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>modelo_trf5 <span class="ot">&lt;-</span> <span class="fu">captcha_load_model</span>(<span class="st">"trf5"</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>captchaDownload<span class="sc">::</span><span class="fu">captcha_oracle</span>(</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">path =</span> <span class="st">"assets/img/"</span>,</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">model =</span> modelo_trf5, </span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">max_ntry =</span> <span class="dv">1</span>,</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">manual =</span> <span class="cn">TRUE</span>, </span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">captcha_access =</span> captchaDownload<span class="sc">:::</span>captcha_access_trf5,</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">captcha_test =</span> captchaDownload<span class="sc">:::</span>captcha_test_trf5</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<pre><code>✔ Acertou!!!</code></pre>
<p>No teste do exemplo, a função acertou, salvando o seguinte arquivo de <em>log</em>. Espaços foram adicionados para facilitar a visualização.</p>
<pre><code>ntry, label , type, result
1,    569328, auto, TRUE</code></pre>
<p>Abaixo, foi colocado um modelo ruim para o TRT, para forçar o modelo a errar todos os chutes. O resultado é o log abaixo</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>modelo <span class="ot">&lt;-</span> <span class="fu">captcha_load_model</span>(<span class="st">"assets/modelo_ruim.pt"</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>captchaDownload<span class="sc">::</span><span class="fu">captcha_oracle</span>(</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">path =</span> <span class="st">"assets/img/"</span>,</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">model =</span> modelo, </span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">max_ntry =</span> <span class="dv">10</span>,</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">manual =</span> <span class="cn">TRUE</span>, </span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">captcha_access =</span> captchaDownload<span class="sc">:::</span>captcha_access_trt,</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">captcha_test =</span> captchaDownload<span class="sc">:::</span>captcha_test_trt</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<pre><code>ℹ Temos 10 candidatos...
ℹ Errou! O chute foi: v2su7w
ℹ Errou! O chute foi: t2su7w
ℹ Errou! O chute foi: v2su7y
ℹ Errou! O chute foi: t2su7y
ℹ Errou! O chute foi: y2su7w
ℹ Errou! O chute foi: v2su7h
ℹ Errou! O chute foi: t2su7h
ℹ Errou! O chute foi: y2su7y
ℹ Errou! O chute foi: v2wu7w
Label: v2xu7w</code></pre>
<p>No novo exemplo, a função errou todos os dez chutes, salvando o seguinte arquivo de <em>log</em>. Espaços foram adicionados para facilitar a visualização. O último valor é um rótulo inserido manualmente.</p>
<pre><code>ntry,  label,   type, result
   1, v2su7w,   auto,  FALSE
   2, t2su7w,   auto,  FALSE
   3, v2su7y,   auto,  FALSE
   4, t2su7y,   auto,  FALSE
   5, y2su7w,   auto,  FALSE
   6, v2su7h,   auto,  FALSE
   7, t2su7h,   auto,  FALSE
   8, y2su7y,   auto,  FALSE
   9, v2wu7w,   auto,  FALSE
  10, 92su7w,   auto,  FALSE
  NA, v2xu7w, manual,   TRUE</code></pre>
<p>Se o parâmetro <code>manual=FALSE</code> e o modelo não consegue acertar o rótulo, a função também adiciona a mensagem:</p>
<pre><code>✖ Errado depois de todas as tentativas...</code></pre>
<p>Em alguns casos, é possível que a função realize menos do que <code>max_ntry</code> chutes. Isso acontece quando a probabilidade do melhor rótulo depois do chute errado é muito pequena, segundo o modelo. Isso é feito pela função <code>captcha_candidates()</code>, que considera como padrão o corte de <code>0.01</code> de probabilidade. Ou seja, na prática, a função testa no máximo os <code>max_ntry</code> rótulos com probabilidades maior que <code>0.01</code> segundo o modelo.</p>
<p>Em resumo, o pacote <code>{captchaDownload}</code> contém toda a parte de <em>web scraping</em> utilizada no desenvolvimento da tese. Adicionalmente, o pacote contém funções para orquestrar o <em>download</em> automático de Captchas parcialmente rotulados, a partir de um modelo inicial e um oráculo.</p>
<p>Os dados fornecidos pelo pacote ficam tanto na forma de imagens rotuladas quanto na forma de arquivos de <em>log</em>, disponibilizados em arquivos <em>CSV</em>. Para lidar com essa estrutura de dados, mais um pacote foi desenvolvido: o <code>{captchaOracle}</code>, definido a seguir.</p>
</section>
<section id="sec-pacote-oracle" class="level2">
<h2 class="anchored" data-anchor-id="sec-pacote-oracle">Pacote captchaOracle</h2>
<p>O pacote <code>{captchaOracle}</code>, assim como o <code>{captchaDownload}</code>, foi desenvolvido para a construção da tese. O pacote, portanto, não apresenta documentação extensiva e suas funções podem não estar com a sintaxe final. Futuramente, o pacote poderá funcionar como novo <em>backend</em> para o pacote <code>{captcha}</code>, aplicando o WAWL como uma alternativa no fluxo de resolução de Captchas definido na Subseção <a href="#sec-captcha-do-zero"><span>A.1.3</span></a>.</p>
<p>O pacote possui quatro funções principais: a <code>captcha_dataset_oracle()</code>, a <code>net_captcha_oracle()</code>, a <code>oracle_loss()</code> e a <code>captcha_accuracy_oracle()</code>. Cada função desempenha um papel similar a seus pares do pacote <code>{captcha}</code>, mas conseguem lidar com a estrutura de dados fornecida pelo oráculo.</p>
<p>A primeira função a ser utilizada é a <code>captcha_dataset_oracle()</code>. Trata-se de uma função similar à <code>captcha_dataset()</code> do pacote <code>{captcha}</code>, mas com um parâmetro adicional, <code>path_logs=</code>, que recebe o caminho dos arquivos de <em>log</em>.</p>
<p>A estrutura de dados no caso do oráculo é mais complexa do que no caso canônico. Na resposta, ao invés de guardar uma matriz <em>one hot</em> para cada Captcha, é armazenada uma lista com várias matrizes <em>one hot</em>, uma para cada tentativa do Captcha. Além disso, é armazenado um vetor <code>z</code>, com zeros e uns, informando se algum rótulo está correto ou se todos os rótulos estão incorretos. A variável <code>z</code> é construída a partir dos nomes dos arquivos, que contém um <code>_1</code> caso o rótulo esteja correto e <code>_0</code> caso contrário. Por último, a imagem de entrada é armazenada da mesma forma que na função <code>captcha_dataset()</code>.</p>
<p>O módulo <code>net_captcha_oracle()</code> faz poucos ajustes à estrutura inicial fornecida pelo módulo <code>net_captcha()</code> do pacote <code>{captcha}</code>. A única modificação da função é que ela recebe um modelo inicial de entrada, transferindo os pesos ajustados do modelo ao novo módulo. O módulo <code>net_captcha_oracle()</code>, inclusive, poderia ser utilizado fora do contexto do WAWL, já que só utiliza os dados de <em>input</em>, que não são alterados.</p>
<p>A função <code>captcha_accuracy_oracle()</code> é utilizada para estimar a acurácia do modelo. Para isso, a função precisa lidar com o fato de que os dados de validação apresentam uma estrutura diferente dos dados de treino, já que estão completamente classificados. No treino, a acurácia é calculada considerando apenas os casos em que a resposta é conhecida. Na validação, a acurácia é calculada considerando-se todas as observações.</p>
<p>Por último, a função <code>oracle_loss()</code> é a que contém a proposta de função de perda do método WAWL. Nos casos corretos, a função de perda é obtida calculando-se uma entropia cruzada simples. Nos casos incorretos, a perda é calculada pela estratégia <code>1-p</code>, ou seja, considerando o complementar da probabilidade de observar os chutes que foram apresentados segundo o modelo.</p>
<p>Em resumo, o pacote <code>{captchaOracle}</code> é o que contém os principais avanços da tese do ponto de vista estatístico. Na prática, é utilizado como <em>backend</em> computacional para ajuste dos modelos que utilizam o oráculo, dentro de um fluxo de trabalho igual ao que é construído para ajuste dos modelos canônicos.</p>
<p>Os códigos para realizar as simulações do modelo foram adicionados na pasta <code>data-raw</code> do pacote <code>{captchaOracle}</code>. Os códigos foram organizados da seguinte forma:</p>
<ul>
<li><code>passo_01_*.R</code>. Contêm os códigos utilizados para ajustar os modelos iniciais. Os códigos são organizados de forma a permitir que vários modelos sejam rodados em paralelo, aproveitando o máximo do poder computacional da máquina utilizada para realizar os ajustes.</li>
<li><code>passo_02_*.R</code>. Contêm os códigos utilizados para construir as bases de treino e validação para o passo 03. Foi o passo mais demorado da simulação, já que envolveu acessar os sites dos tribunais pela <em>internet</em> para obtenção dos Captchas anotados automaticamente. Para realizar a simulação, foram baixados mais de 500.000 Captchas da <em>internet</em>.</li>
<li><code>passo_03_*.R</code>. Contêm os códigos utilizados para ajustar os modelos finais. Os códigos foram organizados de forma similar ao passo 01, mas utilizando as funções desenvolvidas no pacote <code>{captchaOracle}</code> para considerar os dados fornecidos pelo oráculo.</li>
</ul>
<p>Por fim, foi adicionado também um script <code>report.R</code>, que monta as bases principais e os resumos dos modelos ajustados. As bases fornecidas pelo último <em>script</em> foram adicionadas ao repositório da tese.</p>


<div id="refs" class="references csl-bib-body" data-entry-spacing="1" role="doc-bibliography" style="display: none">
<div id="ref-tensorflow" class="csl-entry" role="doc-biblioentry">
ALLAIRE, J.; TANG, Y. tensorflow: R Interface to ’TensorFlow’. 2022. Disponível em: &lt;<a href="https://CRAN.R-project.org/package=tensorflow">https://CRAN.R-project.org/package=tensorflow</a>&gt;.
</div>
<div id="ref-piggyback" class="csl-entry" role="doc-biblioentry">
BOETTIGER, C.; HO, T. piggyback: Managing Larger Data on a GitHub Repository. 2022. Disponível em: &lt;<a href="https://CRAN.R-project.org/package=piggyback">https://CRAN.R-project.org/package=piggyback</a>&gt;.
</div>
<div id="ref-torch-2" class="csl-entry" role="doc-biblioentry">
FALBEL, D.; LURASCHI, J. torch: Tensors and Neural Networks with ’GPU’ Acceleration. 2022. Disponível em: &lt;<a href="https://CRAN.R-project.org/package=torch">https://CRAN.R-project.org/package=torch</a>&gt;.
</div>
<div id="ref-kuhn2019" class="csl-entry" role="doc-biblioentry">
KUHN, M.; JOHNSON, K. <strong>Feature engineering and selection: A practical approach for predictive models</strong>. CRC Press, 2019.
</div>
<div id="ref-decryptr" class="csl-entry" role="doc-biblioentry">
TRECENTI, J. et al. decryptr: An extensible API for breaking captchas. 2022.
</div>
<div id="ref-reticulate" class="csl-entry" role="doc-biblioentry">
USHEY, K.; ALLAIRE, J.; TANG, Y. reticulate: Interface to ’Python’. 2022. Disponível em: &lt;<a href="https://CRAN.R-project.org/package=reticulate">https://CRAN.R-project.org/package=reticulate</a>&gt;.
</div>
<div id="ref-usethis" class="csl-entry" role="doc-biblioentry">
WICKHAM, H.; BRYAN, J.; BARRETT, M. usethis: Automate Package and Project Setup. 2022. Disponível em: &lt;<a href="https://CRAN.R-project.org/package=usethis">https://CRAN.R-project.org/package=usethis</a>&gt;.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiada");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiada");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./bibliografia.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Bibliografia</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->



</body></html>