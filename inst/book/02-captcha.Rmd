# Captchas

> contar a história dos captchas como uma luta de classes: geradores e classificadores

> na história, ir citando os papers que vão aparecendo

> o advento do recaptcha

> quando surgir o primeiro classificador com convnets, definir de forma mais detalhada


Vamos usar como exemplo o CAPTCHA do Tribunal de Justiça de Minas Gerais (TJMG). Nesse caso, temos $L=4$ e $|\mathcal A|=10$, apenas os dez algarismos.

```{r dlimg1, eval=FALSE, echo=FALSE}
arq_captcha <- decryptr::download_captcha("tjmg", n = 1, path = 'assets/img/captcha')
```

A Figura \@ref(fig:tjmg1) mostra um exemplo do captcha do TJMG. Podemos notar a utilização de distorção de catacteres e adição de linhas ligando os dígitos como formas de evitar a resolução automática.

```{r tjmg1, fig.height=1.5, fig.width=4, fig.cap='CAPTCHA do TJMG.', eval=FALSE, echo=FALSE}
library(decryptr)
arq_captcha <- "assets/img/captcha/captcha28485fae0376.jpeg"
arq_captcha  %>% 
  read_captcha() %>% 
  dplyr::first() %>% 
  plot()
```

Nesse caso, podemos resolver o problema da segmentação realizando cortes fixos na imagem. Podemos também limitar os eixos `x`, tirando os espaços vazios à esquerda e à direita e `y`, removendo espaços superiores e inferiores. Por último, transformamos a imagem em escala de cinza. O resultado dessas operações de pré-processamento estão na Figura \@ref(fig:tjmg2).

```{r tjmg2, fig.height=1.5, fig.width=4, fig.cap='CAPTCHA do TJMG após segmentação.', echo=FALSE, eval=FALSE}
op <- graphics::par(mar = rep(0, 4))
arq_captcha %>% 
  read_captcha() %>% 
  dplyr::first() %>% 
  with(x) %>% 
  magrittr::extract(-c(1:7, 34:dim(.)[1]), -c(1:06, 107:dim(.)[2]), TRUE) %>%
  grDevices::as.raster() %>% 
  graphics::plot()
abline(v = 20 * 1:4, col = 'red')
abline(h = c(0, 26), col = 'blue')
```

O resultado são cinco imagens de dimensões `26x20`, associadas a cada caractere. O próximo passo é transformar o banco de dados num formato tratável por modelos tradicionais de regressão. Para isso, colocamos cada pixel em uma coluna da nossa base de dados. No caso do TJMG, cada CAPTCHA gera uma tabela de 5 linhas e 520 (`26 * 20`) colunas. A Tabela \@ref(tab:imgsep) mostra as primeiras seis colunas dessa base. 

```{r imgsep, echo=FALSE, eval=FALSE}
arq_captcha %>% 
  read_captcha() %>% 
  dplyr::first() %>% 
  with(x) %>% 
  magrittr::extract(-c(1:7, 34:dim(.)[1]), -c(1:06, 107:dim(.)[2]), TRUE) %>%
  tibble::as_tibble() %>% 
  tibble::rownames_to_column('y') %>% 
  tidyr::gather(x, value, -y) %>% 
  dplyr::mutate_at(dplyr::vars(x, y), dplyr::funs(readr::parse_number)) %>% 
  dplyr::mutate(letra = (x - 1) %/% 20 + 1, x = x - (letra - 1) * 20) %>% 
  dplyr::mutate_at(dplyr::vars(x, y), dplyr::funs(sprintf('%02d', .))) %>% 
  tidyr::unite(xy, x, y) %>% 
  tidyr::spread(xy, value, sep = '') %>% 
  dplyr::mutate(y = c('7', '3', '2', '4', '6')) %>% 
  dplyr::select(y, dplyr::everything(), -letra) %>% 
  dplyr::select(1:7) %>%
  dplyr::mutate_at(dplyr::vars(-y), dplyr::funs(round(., 3))) %>% 
  knitr::kable(caption = "Base de dados montada a partir de imagem segmentada.")
```

Agora basta rodar o mesmo para toda a base de treino e rodar um modelo. Nesse exemplo, utilizamos uma base de 1500 CAPTCHAs classificados. O resultado após o pré-processamento é uma base com 7500 linhas e 520 colunas. Escolhemos manter 6000 linhas para treino e as 1500 restantes para teste. Utilizamos um modelo de florestas aleatórias para o exemplo [@breiman2001random].

```{r carregabd, message=FALSE, warning=FALSE, eval=FALSE, echo=FALSE}
dados <- readRDS('data/dados_segment.rds') %>% 
  dplyr::mutate(y = factor(y))
# monta bases de treino e teste
set.seed(4747) # reprodutibilidade
ids_treino <- sample(seq_len(nrow(dados)), 6000, replace = FALSE)
d_train <- dados[ids_treino, ]
d_test <- dados[-ids_treino, ]
model_rf <- randomForest::randomForest(y ~ . - captcha_id, data = d_train) 
```

O resultado do modelo pode ser verificado na Tabela \@ref(tab:errosTJMG), que mostra os observados *versus* preditos na base de teste. O acerto foi de 99.6% em cada caractere. Assumindo que o erro não depende da posição do caractere no CAPTCHA, o acerto para a imagem completa é de aproximadamente 98%.

```{r errosTJMG, eval=FALSE, echo=FALSE}
library(randomForest)
dados <- readRDS('data/dados_segment.rds') %>% 
  dplyr::mutate(y = factor(y))
# monta bases de treino e teste
set.seed(4747) # reprodutibilidade
ids_treino <- sample(seq_len(nrow(dados)), 6000, replace = FALSE)
d_train <- dados[ids_treino, ]
d_test <- dados[-ids_treino, ]
model_rf <- readRDS("data/model_rf.rds")
d_test %>% 
  dplyr::mutate(pred = predict(model_rf, newdata = .)) %>% 
  dplyr::count(y, pred) %>% 
  tidyr::spread(pred, n, fill = '.') %>% 
  tibble::remove_rownames() %>% 
  knitr::kable(caption = 'Tabela de acertos e erros.')
```

O resultado para o TJMG é bastante satisfatório, mas não generaliza para outros CAPTCHAs. Tome por exemplo o CAPTCHA da Receita Federal (RFB) da Figura \@ref(fig:generalize). Nesse caso, a posição dos caracteres muda significativamente de imagem para imagem, e assim fica difícil cortar em pedaços.

```{r generalize, echo=FALSE, out.width = '32%', fig.cap="CAPTCHA Receita Federal", fig.align="center", eval=FALSE}
fs::dir_ls('assets/img/captcha/rfb')[1] %>% 
  decryptr::read_captcha() %>% 
  purrr::walk(plot)
```

A mesma técnica aplicada ao CAPTCHA RFB apresentou acerto de 78.8% do caractere, o que equivale a apenas 23.8% de acerto para toda a imagem. Claro que seria possível melhorar o poder preditivo com ajustes nos hipeparâmetros do modelo, mas o problema essencial nesse caso está na qualidade segmentação, e não na classificação dos caracteres.

Outro problema dessa técnica é que ela é incapaz de trabalhar com CAPTCHAs de comprimento variável. Nesse caso, seria necessário construir um modelo não supervisionado para identificar a posição das letras, o que adiciona um grau a mais de complexidade na resolução do CAPTCHA.

Por isso, faz-se necessária uma abordagem que trabalha com problema completo, sem passar explicitamente pela fase de segmentação. Ao invés de cortar a imagem, vamos extrair detalhes da imagem completa automaticamente e utilizar essas características como variáveis preditoras num modelo de regressão. Chamaremos essa abordagem de *força bruta*.

## Força-bruta


### Redes neurais



#### Regressão logística



```{r echo=FALSE, out.width="40%", fig.align="center", eval=FALSE}
knitr::include_graphics("assets/img/glm.png")
```





#### Extensão para redes neurais



#### Sinônimos e generalizações



### A operação de convolução



```{r, out.width="30%", echo=FALSE, no.mar=TRUE, eval=FALSE, fig.align="center"}
library(magrittr)
"assets/img/emoji3.png" %>% 
  magick::image_read() %>% 
  plot()
```



```{r emoji-horiz, no.mar=TRUE, out.width="30%", fig.cap="Figura após aplicação de convolução.", echo=FALSE, eval=FALSE, fig.align="center"}
kern_horizontal <- matrix(c(-1,-1,-1,0,0,0,1,1,1), ncol = 3, byrow = TRUE)
convolve <- function(img, kern) {
  # monta a bordinha na imagem. A borda deve ter (tamanho kernel) / 2,
  # de tamanho, arredondando para baixo
  pad <- floor(dim(kern)[1] / 2)
  img_pad <- matrix(0, nrow = nrow(img) + 2 * pad, ncol = ncol(img) + 2 * pad)
  img_pad[pad + 1:nrow(img), pad + 1:ncol(img)] <- img[,,1]
  # aplica a convolução nos pontos da imagem
  for (i in seq_len(nrow(img))) {
    for (j in seq_len(ncol(img))) {
      img[i, j, 1] <- sum(img_pad[i + 0:(2 * pad), j + 0:(2 * pad)] * kern)
    }
  }
  img[,,2] <- img[,,3] <- img[,,1]
  img
}
"assets/img/emoji3.png" %>% 
  decryptr:::load_image() %>% 
  convolve(kern_horizontal) %>% 
  magick::image_read() %>% 
  plot()
```



```{r, no.mar=TRUE, out.width="30%", echo=FALSE, eval=FALSE, fig.align="center"}
kern_vertical <- rbind(c(-1, 0, 1),
                       c(-1, 0, 1),
                       c(-1, 0, 1))
"assets/img/emoji3.png" %>% 
  decryptr:::load_image() %>% 
  convolve(kern_vertical) %>% 
  magick::image_read() %>% 
  plot()
```

A aplicação de convoluções em CAPTCHAs é direta. Nesse caso, vamos adicionar uma constante numérica ao resuldado da convolução. Isso pode auxiliar na visualização, pois controlamos os valores que ficam dentro do intervalo $[0,1]$. Mais adiante veremos que esse será o intercepto da regressão.

Vamos partir do CAPTCHA da RFB abaixo

```{r, fig.height=1, fig.width=3.6, no.mar=TRUE, echo=FALSE, eval=FALSE, fig.align="center"}
arq <- "assets/img/captcha41367a06c5a.png"
op <- graphics::par(mar = rep(0, 4))
arq %>% 
  decryptr:::load_image() %>% 
  magick::image_read() %>% 
  plot()
```


```{r, echo=FALSE}
add_bias <- function (x, b) x + b
```

Esse é o resultado de adicionar o kernel vertical e bias de `0.6`.

```{r, fig.height=1, fig.width=3.6, no.mar=TRUE, echo=FALSE, eval=FALSE, fig.align="center"}
op <- graphics::par(mar = rep(0, 4))
arq %>% 
  decryptr:::load_image() %>% 
  convolve(kern_vertical) %>% 
  add_bias(.6) %>% 
  magick::image_read() %>% 
  plot()
```

Em seguida observamos o kernel horizontal. Note que identificamos padrões das linhas horizontais que tentam atrapalhar a visão das letras.

```{r, fig.height=1, fig.width=3.6, no.mar=TRUE, echo=FALSE, eval=FALSE, fig.align="center"}
op <- graphics::par(mar = rep(0, 4))
arq %>% 
  decryptr:::load_image() %>% 
  convolve(kern_horizontal) %>% 
  add_bias(.6) %>% 
  magick::image_read() %>% 
  plot()
```



### Redes neurais convolucionais



### Resultados

Até o momento, aplicamos os modelos de redes neurais convolucionais para cinco CAPTCHAs distintos. Os modelos foram treinados a partir de bases de treino com aproximadamente dez mil exemplos para cada CAPTCHA. Os resultados da aplicação dos modelos estão na Tabela \@ref(tab:resultados). Essas taxas foram calculadas com base em 100 novos CAPTCHAs baixados da internet após o ajuste do modelo. Podemos observar que as taxas de acerto são todas muito próximas de 100%. No mínimo essas taxas estão muito próximas do que seres humanos conseguiriam acertar.

```{r resultados, eval=FALSE}
tibble::tibble(
  Imagem = c(knitr::include_graphics("assets/img/rfb.png"), 
             "![](assets/img/trt.png)", 
             "![](assets/img/tjmg.jpeg)", 
             "![](assets/img/rsc.png)",
             "![](assets/img/cadesp.png)"), 
  Nome = c("RFB", "TRT", "TJMG", "RSC", "CADESP"), 
  `Taxa de acerto` = c("98%", "98%", "100%", "99%", "98%"), 
) %>% 
  knitr::kable(caption = "Resultados da aplicação dos modelos.")
```

Os resultados positivos da aplicação dos modelos força-bruta pode motivar a pergunta: o problema está completamente resolvido? De fato, podemos dizer que CAPTCHAs de imagem baseados em textos são problemas resolvidos, desde que exista uma base de dados classificada. No entanto, esses modelos não funcionam para novos CAPTCHAs e também erram se fizermos pequenas alterações nas imagens. Veremos mais detalhes desse problema no próximo capítulo.




> quando surgir o primeiro classificador com GAN, definir de forma mais detalhada

