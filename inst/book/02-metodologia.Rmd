# Metodologia

<!-- ----------------------------------------------------------- -->

Trabalhos de estatística costumam ter uma parte de metodologia maior do que introdução e resultados. Essa tese não será diferente. A metodologia é essencial para garantir a reprodutibilidade do trabalho, pois, mais do que simplesmente apresentar o código utilizado, mostra o passo a passo, as dores e as decisões difíceis que tiveram de ser tomadas para concluir o projeto.

O capítulo está organizado em três seções: definição do problema, dados e simulações. A primeira mostra a base matemática do problema estudado e as escolhas de sintaxe e terminologias. A segunda descreve as fontes de dados e o processo de coleta, já que a base foi construída totalmente do zero. A terceira mostra como foram planejadas as simulações para verificar se a solução proposta funciona bem empiricamente.

Pode parecer estranho, a princípio, uma seção de definições no capítulo de metodologia. No entanto ela é muito importante para as discussões que seguem. Como será mostrado mais adiante, a pesquisa também apresenta resultados teóricos da solução proposta, mas para apresentá-los é necessário escrever as definições do objeto matemático que está sendo estudado. 

Uma decisão mais difícil de tomar na parte teórica foi sobre a parte de redes neurais. No início do projeto de doutorado, a pesquisa em redes neurais nos departamentos de estatística era uma novidade, sofrendo até certo preconceito por ser um modelo "caixa-preta". Com o passar do tempo, no entanto, a área está ficando cada vez mais popular, inclusive com pessoas da graduação fazendo iniciação científica neste tema. Por isso, optou-se por trabalhar nas pontes entre os modelos clássicos de estatística e os modelos de redes neurais, mas sem todos os detalhes técnicos que podem ser encontrados com qualidade em livros mais completos. Espera-se que o conteúdo possa ser utilizado por pessoas interessadas em ensinar redes neurais para estudantes de estatística.

Na seção de dados, procurou-se apresentar a metodologia de coleta com alto nível de detalhe. Isso foi feito porque a área de raspagem de dados não é comum para estudantes de estatística, existindo até uma percepção entre acadêmicos de que trata-se de uma área separada da estatística. Uma das hipóteses de pesquisa, bem como a solução técnica apresentada neste trabalho é justamente uma ponte entre as duas áreas, justificando um detalhamento maior dos conceitos.

Implementações de raspagem de dados, no entanto, são inconstantes. Um site de interesse pode mudar sua estrutura ou simplesmente trocar o Captcha para um reCaptcha da noite para o dia, alterando completamente o fluxo de coleta. Isso aconteceu, inclusive, com um dos sites mais importantes dentro do contexto da jurimetria: em 2018, o Tribunal de Justiça de São Paulo (TJSP) passou a utilizar o reCaptcha para bloquear ferramentas automatizadas. Qualquer código ou fluxo para acessar as fontes de dados consideradas no trabalho, portanto, estarão datadas no momento da publicação. Por isso, optou-se por apresentar essa parte de forma genérica e deixar as atualizações para os códigos, que estão disponíveis publicamente e serão mantidos com contribuições da comunidade.

Na seção de simulações, procurou-se descrever os passos dados em detalhe. Nesse caso, a escolha do detalhamento se deu por motivos puramente científicos, para que qualquer pessoa possa reproduzir os passos dados, possibilitanto replicá-los para outros exemplos com alterações mínimas no fluxo e sugerir melhorias.

## Definição do problema

Nesta seção, buscou-se definir o problema trabalhado de forma precisa. Escolheu-se fazer isso de baixo para cima, a partir da estrutura de dados e depois do problema estatístico. Cabe, no entanto, um adiantamento do que vem pela frente para facilitar a leitura.

O problema a ser trabalhado é um caso *aprendizado fracamente supervisionado*, que é uma generalização do aprendizado supervisionado e também do aprendizado *semi-supervisionado*. Usualmente, a área de aprendizado estatístico (ou aprendizado de máquinas) se concentra em dois tipos de problemas principais: o aprendizado supervisionado e o aprendizado não supervisionado. É possível observar essa classificação em diversos livros-texto da área (XXX). Isso ocorre principalmente por fins didáticos, pois é mais fácil passar os modelos que fazem parte de cada área.

No entanto, a estatística evolui com os problemas que ocorrem no mundo. E, no mundo, os problemas nem sempre recaem em uma ou outra categoria. O que temos, na verdade, é que os problemas não supervisionados e supervisionados estão conectados, desde que o objetivo de uma pesquisa seja o de predizer valores (regressão) ou categorias (classificação).

Nesse sentido, uma área que ficou popular nos últimos anos, até por conta dos avanços na área de Deep Learning, é o aprendizado semi-supervisionado. Trata-se de uma classe de problemas contendo uma amostra completamente anotada e uma amostra sem anotações. A amostra sem anotações é usada para compreender como os dados foram gerados, e os parâmetros podem ser compartilhados com a parte supervisionada do modelo. Isso poderia indicar que existem três classes de problemas: o não supervisionado, o supervisionado e o semi-supervisionado.

Mas isso também não representa todas as classes de problemas.

Em muitas aplicações reais, obter uma anotação completa e correta pode ser custoso ou até impraticável. Além disso por envolver trabalho humano, é comum que classificações contenham erros. Para lidar com esses casos existe uma área, que generaliza as anteriores, que é o aprendizado fracamente supervisionado.

O problema fracamente supervisionado será o final da jornada. Ela começa de onde deve começar, com aqueles que são objeto de análise deste trabalho: os Captchas.

### Captcha

Captcha é um *desafio* do tipo *desafio-resposta* usado para determinar se o usuário do sistema é um humano. Existem diversos tipos de Captcha diferentes, que envolvem desde identificar textos em imagens até resolver expressões matemáticas complexas. O foco deste trabalho reside nos Captchas baseados em imagens rotuladas, que é o tipo mais comum.

O fluxo completo de um Captcha envolve cinco componentes: um *rótulo*, um *gerador*, uma *imagem*, um agente e um *oráculo*. Um ciclo do Captcha é completado ao seguir os passos:

1. O rótulo é definido, usualmente com algum procedimento aleatório.
2. A imagem é gerada a partir do rótulo e apresentada para o agente.
3. O agente preenche sua resposta a partir da imagem (que pode estar certo ou errado)
4. O oráculo verifica se a resposta está correta.
5. Dependendo da resposta, o agente é direcionado para a página autenticada ou para uma página de erro.

A Figura \@ref(fig:esquema-captcha) esquematiza o fluxo do Captcha.

```{r esquema-captcha, fig.cap="Fluxo do Captcha"}

knitr::include_graphics("assets/img/esquema-captcha.png")
```

#### Imagem e rótulo

A imagem é uma matriz $\mathbf x = \{x_{nmr} \in [0,1]\}_{N\times M \times R}$, contendo padrões que, a partir da análise humana, levam ao rótulo do Captcha. O *rótulo* dado por um vetor de caracteres $\mathbf c = [c_1,\dots,c_L]^\top$. O comprimento $L$ pode ser fixo ou variável, ou seja, duas imagens criadas pelo mesmo gerador podem vir com comprimentos diferentes. Nas definições que seguem vamos considerar $L$ como fixo. Na Seção \ref(modelando-resposta) serão mostradas algumas opções para quando $L$ é variável.

Os elementos do vetor $\mathbf c$ fazem parte de um alfabeto $\mathcal A$, com cardinalidade $|\mathcal A|$, finito e conhecido. O alfabeto contém todos os possíveis caracteres que podem aparecer na imagem. Na maioria dos casos, $\mathcal A$ corresponde a uma combinação de algarismos arábicos (0-9) e letras do alfabeto latino (a-z), podendo diferenciar ou não as letras maiúsculas e minúsculas[^letra-numero].

[^letra-numero]: existem exemplos de Captchas baseados em imagens que não são limitados a letras e números para constituir o rótulo (XXX). Como esses casos não aparecem nas aplicações práticas de interesse, estão fora do escopo do trabalho.

O elemento da matriz $x_{nm\cdot}$ é denominado *pixel*. Um pixel representa a menor unidade possível da imagem. Em uma imagem colorida, por exemplo, temos $R=3$. Nesse caso, um pixel é um vetor de três dimensões com valores entre zero e um, representando a intensidade de vermelho, verde e azul da coordenada $(n, m)$ da imagem. Numa imagem em escala de cinza, por exemplo, temos $R=1$ e o pixel, de uma dimensão, representa a intensidade do cinza, sendo 1 o equivalente da cor branca e 0 o preto.

**Exemplo**. Vamos usar como exemplo o Captcha do Tribunal de Justiça de Minas Gerais (TJMG). Nesse caso, temos $L=4$ e $|\mathcal A|=10$, apenas os dez algarismos arábicos.

A **variável resposta** $\mathbf y \in \{1, \dots, |\mathcal A|\}^L$ é um vetor de índices que identificam os caracteres $c_j \in \mathcal A$ do Captcha. Cada elemento de $\mathbf y$ representa um elemento do alfabeto $\mathcal A$.

Um problema de resolver o Captcha diretamente é que a variável resposta $\mathbf y$ tem um número exponencial de combinações. Na formulação de $\mathbf y$ apresentada, a resposta é uma palavra de $L$ caracteres, sendo que cada caractere $c_j$ pode ter $|\mathcal A|$ valores. Nessa construção, o total de combinações é $|\mathcal A|^L$.

Por exemplo, um Captcha com $L=6$ letras e $|\mathcal A| = 36$ possibilidades em cada letra (26 letras do alfabeto latino e 10 algarismos arábicos), possui um total de 2.176.782.336 ($>$ 2 bilhões) combinações. Modelar essas imagens diretamente através de uma única variável resposta categórica é tecnicamente inviável.

Uma forma alternativa de definir a variável resposta é tratando-a como uma __multinomial__ __multivariada__ (XXX). A resposta é multivariada porque temos $L$ caracteres na imagem e multinomial porque temos $|\mathcal A|$ possíveis caracteres em cada posição. Dessa forma, podemos pensar que o modelo que resolve o Captcha envolve $L$ classificadores com resposta multinomial, cada um dando conta de uma das posições dos índices. Os classificadores podem ser independentes e contar com etapas de pré-processamento separadas.

Como o alfabeto de um Captcha é fixo, podemos representar o rótulo com um matriz de valores *dummy*. Essa matriz terá $L$ linhas e $|A|$ colunas. Em cada linha, a matriz terá exatamente um valor $1$ na posição correspondente ao caractere da resposta e o valor $0$ em todas as outras posições. Por exemplo, podemos representar da seguinte forma:

$$
\mathbf{y} = \left[\begin{array}{c}
     3  \\
     4 \\
     9 \\
     1
\end{array}\right] \rightarrow \left[\begin{array}{cccccccccc}
    0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
    0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
    0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0
\end{array}\right]
$$

A forma *dummy* da resposta será bastante utilizada, pois facilita o trabalho na parte computacional. Como será visto mais adiante, o modelo de rede neural gerará uma matriz de probabilidades que somam $1$ em cada linha, com as probabilidades de cada caractere em cada posição.

#### Gerador

O **gerador** é uma função $g$ que recebe um rótulo como entrada e devolve uma imagem como saída. Um bom gerador é aquele que é capaz de gerar uma imagem fácil de interpretar por humanos, mas difícil de se resolver por robôs.

#### Oráculo

Para definir o oráculo, utilizou-se uma terminologia que é facilmente encaixada com a teoria de aprendizado fracamente supervisionado. Seja $g \in \mathcal Y ^ {\mathcal X}$ um modelo utilizado para predizer o Captcha e seja $X_{n+1}$ um \textbf{novo} Captcha que é observado, com seu rótulo $y_{n+1}$, desconhecido.

O oráculo é uma função $\mathcal O: \mathcal Y \rightarrow 2^{\mathcal Y}$, com

$$
\mathcal O(g(X_{n+1})) = \left\{\begin{array}{ll}
    \{y_{n+1}\}, & \text{ se } y_{n+1} = g(X_{n+1})  \\
    \mathcal Y \setminus \{g(X_{n+1})\}, & \text{ se } y_{n+1} \neq g(X_{n+1})
\end{array}\right.
$$

Explicando a função: quando a função $g$ acerta o rótulo, o oráculo retorna o próprio rótulo. Quando a função erra o rótulo, o oráculo retorna uma lista com todos os outros possíveis rótulos para $X_{n+1}$, incluindo o valor correto $y_{n+1}$.

A Figura \@ref(fig:esquema-oraculo) mostra o funcionamento do oráculo no exemplo do TJMG. Quando a predição é igual ao rótulo, o resultado apresentado é o valor um, indicando que o rótulo está correto. Quando a predição é diferente do rótulo, o resultado apresentado é o valor zero, indicando que o valor testado está incorreto e que, portanto, o rótulo real é um dentre todos os outros possíveis rótulos.

```{r esquema-oraculo, fig.cap="Esquema mostrando o funcionamento do oráculo."}
knitr::include_graphics("assets/img/esquema-oraculo.png")
```

É possível generalizar naturalmente o oráculo para múltiplos chutes mudando a definição da função preditiva. Seja $h:\mathcal X \longrightarrow \mathcal Y ^ k$ uma função que retorna um conjunto dos $k$ rótulos mais prováveis, $k\in \mathbb N$, $k\geq 1$, com $X_{n+1}$ e $y_{n+1}$ como definidos anteriormente. Então o oráculo é uma função $\mathcal O: \mathcal Y^k \rightarrow 2^{\mathcal Y}$, com

$$
\mathcal O(h(X_{n+1})) = \left\{\begin{array}{ll}
    \{y_{n+1}\}, & \text{ se } y_{n+1} \in h(X_{n+1})  \\
   \mathcal Y \setminus h(X_{n+1}), & \text{ se } y_{n+1} \notin h(X_{n+1})
\end{array}\right..
$$

#### Fatos estilizados

Captchas costumam ter dimensões relativamente pequenas, com a altura $N$ variando entre 30 e 200 \textit{pixels} e a largura $M$ variando entre 100 e 300 \textit{pixels}. As imagens costumam ser retangulares para comportar várias letras, ou seja, geralmente $M > N$. O valor de $R$ é 1 para imagens em escala de cinza e 3 para imagens coloridas.

Historicamente, uma alternativa para resolver Captchas é separando o problema em duas tarefas: segmentar e classificar. A tarefa de segmentação consiste em receber uma imagem com várias letras e detectar pontos de corte, separando-a em várias imagens de uma letra. Já a classificação consiste em receber uma imagem com uma letra e identificar o caractere correspondente. Nesse caso, a resposta é reduzida para $|\mathcal A|$ categorias, que cresce linearmente e, portanto, tratável.

A tarefa de resolver Captchas também poderia ser vista como um problema de reconhecimento óptico de caracteres (\textit{Optical Character Recognition}, OCR). No entanto, as distorções encontradas em Captchas são bem diferentes das distorções encontradas em textos escaneados, que são o objeto de aplicação de ferramentas de OCR. Por esse motivo, as ferramentas usuais de OCR apresentam resultados pouco satisfatórios em vários Captchas.

As distorções encontradas em Captchas podem ser agrupadas em distorções para dificultar a segmentação e distorções para dificultar a classificação. Na parte de classificação, as principais formas de dificultar o trabalho dos modelos são i) mudar as fontes (serifa ou sem serifa ou negrito/itálico, por exemplo), ii) mudar letras minúsculas para maiúsculas e iii) adicionar distorções nos caracteres. Já na parte de segmentação, as principais formas são i) colar os caracteres e ii) adicionar linhas ligando os dígitos. Essas técnicas são combinadas com a adição de ruído e distorção nas imagens completas para compor a imagem final.

#### Exemplo

Vamos usar como exemplo o CAPTCHA do Tribunal de Justiça de Minas Gerais (TJMG). Nesse caso, temos $L=4$ e $|\mathcal A|=10$, apenas os dez algarismos.

```{r dlimg1, eval=FALSE, echo=FALSE}
arq_captcha <- decryptr::download_captcha("tjmg", n = 1, path = 'assets/img/captcha')
```

A Figura \@ref(fig:tjmg1) mostra um exemplo do captcha do TJMG. Podemos notar a utilização de distorção de catacteres e adição de linhas ligando os dígitos como formas de evitar a resolução automática.

```{r tjmg1, fig.height=1.5, fig.width=4, fig.cap='CAPTCHA do TJMG.', eval=FALSE, echo=FALSE}
library(decryptr)
arq_captcha <- "assets/img/captcha/captcha28485fae0376.jpeg"
arq_captcha  %>% 
  read_captcha() %>% 
  dplyr::first() %>% 
  plot()
```

Nesse caso, podemos resolver o problema da segmentação realizando cortes fixos na imagem. Podemos também limitar os eixos `x`, tirando os espaços vazios à esquerda e à direita e `y`, removendo espaços superiores e inferiores. Por último, transformamos a imagem em escala de cinza. O resultado dessas operações de pré-processamento estão na Figura \@ref(fig:tjmg2).

```{r tjmg2, fig.height=1.5, fig.width=4, fig.cap='CAPTCHA do TJMG após segmentação.', echo=FALSE, eval=FALSE}
op <- graphics::par(mar = rep(0, 4))
arq_captcha %>% 
  read_captcha() %>% 
  dplyr::first() %>% 
  with(x) %>% 
  magrittr::extract(-c(1:7, 34:dim(.)[1]), -c(1:06, 107:dim(.)[2]), TRUE) %>%
  grDevices::as.raster() %>% 
  graphics::plot()
abline(v = 20 * 1:4, col = 'red')
abline(h = c(0, 26), col = 'blue')
```

O resultado são cinco imagens de dimensões `26x20`, associadas a cada caractere. O próximo passo é transformar o banco de dados num formato tratável por modelos tradicionais de regressão. Para isso, colocamos cada pixel em uma coluna da nossa base de dados. No caso do TJMG, cada CAPTCHA gera uma tabela de 5 linhas e 520 (`26 * 20`) colunas. A Tabela \@ref(tab:imgsep) mostra as primeiras seis colunas dessa base.

```{r imgsep, echo=FALSE, eval=FALSE}
arq_captcha %>% 
  read_captcha() %>% 
  dplyr::first() %>% 
  with(x) %>% 
  magrittr::extract(-c(1:7, 34:dim(.)[1]), -c(1:06, 107:dim(.)[2]), TRUE) %>%
  tibble::as_tibble() %>% 
  tibble::rownames_to_column('y') %>% 
  tidyr::gather(x, value, -y) %>% 
  dplyr::mutate_at(dplyr::vars(x, y), dplyr::funs(readr::parse_number)) %>% 
  dplyr::mutate(letra = (x - 1) %/% 20 + 1, x = x - (letra - 1) * 20) %>% 
  dplyr::mutate_at(dplyr::vars(x, y), dplyr::funs(sprintf('%02d', .))) %>% 
  tidyr::unite(xy, x, y) %>% 
  tidyr::spread(xy, value, sep = '') %>% 
  dplyr::mutate(y = c('7', '3', '2', '4', '6')) %>% 
  dplyr::select(y, dplyr::everything(), -letra) %>% 
  dplyr::select(1:7) %>%
  dplyr::mutate_at(dplyr::vars(-y), dplyr::funs(round(., 3))) %>% 
  knitr::kable(caption = "Base de dados montada a partir de imagem segmentada.")
```

Agora basta rodar o mesmo para toda a base de treino e rodar um modelo. Nesse exemplo, utilizamos uma base de 1500 CAPTCHAs classificados. O resultado após o pré-processamento é uma base com 7500 linhas e 520 colunas. Escolhemos manter 6000 linhas para treino e as 1500 restantes para teste. Utilizamos um modelo de florestas aleatórias para o exemplo [@breiman2001random].

```{r carregabd, message=FALSE, warning=FALSE, eval=FALSE, echo=FALSE}
dados <- readRDS('data/dados_segment.rds') %>% 
  dplyr::mutate(y = factor(y))
# monta bases de treino e teste
set.seed(4747) # reprodutibilidade
ids_treino <- sample(seq_len(nrow(dados)), 6000, replace = FALSE)
d_train <- dados[ids_treino, ]
d_test <- dados[-ids_treino, ]
model_rf <- randomForest::randomForest(y ~ . - captcha_id, data = d_train) 
```

O resultado do modelo pode ser verificado na Tabela \@ref(tab:errosTJMG), que mostra os observados *versus* preditos na base de teste. O acerto foi de 99.6% em cada caractere. Assumindo que o erro não depende da posição do caractere no CAPTCHA, o acerto para a imagem completa é de aproximadamente 98%.

```{r errosTJMG, eval=FALSE, echo=FALSE}
library(randomForest)
dados <- readRDS('data/dados_segment.rds') %>% 
  dplyr::mutate(y = factor(y))
# monta bases de treino e teste
set.seed(4747) # reprodutibilidade
ids_treino <- sample(seq_len(nrow(dados)), 6000, replace = FALSE)
d_train <- dados[ids_treino, ]
d_test <- dados[-ids_treino, ]
model_rf <- readRDS("data/model_rf.rds")
d_test %>% 
  dplyr::mutate(pred = predict(model_rf, newdata = .)) %>% 
  dplyr::count(y, pred) %>% 
  tidyr::spread(pred, n, fill = '.') %>% 
  tibble::remove_rownames() %>% 
  knitr::kable(caption = 'Tabela de acertos e erros.')
```

O resultado para o TJMG é bastante satisfatório, mas não generaliza para outros CAPTCHAs. Tome por exemplo o CAPTCHA da Receita Federal (RFB) da Figura \@ref(fig:generalize). Nesse caso, a posição dos caracteres muda significativamente de imagem para imagem, e assim fica difícil cortar em pedaços.

```{r generalize, echo=FALSE, out.width = '32%', fig.cap="CAPTCHA Receita Federal", fig.align="center", eval=FALSE}
fs::dir_ls('assets/img/captcha/rfb')[1] %>% 
  decryptr::read_captcha() %>% 
  purrr::walk(plot)
```

A mesma técnica aplicada ao CAPTCHA RFB apresentou acerto de 78.8% do caractere, o que equivale a apenas 23.8% de acerto para toda a imagem. Claro que seria possível melhorar o poder preditivo com ajustes nos hipeparâmetros do modelo, mas o problema essencial nesse caso está na qualidade segmentação, e não na classificação dos caracteres.

Outro problema dessa técnica é que ela é incapaz de trabalhar com CAPTCHAs de comprimento variável. Nesse caso, seria necessário construir um modelo não supervisionado para identificar a posição das letras, o que adiciona um grau a mais de complexidade na resolução do CAPTCHA.

Por isso, faz-se necessária uma abordagem que trabalha com problema completo, sem passar explicitamente pela fase de segmentação. Ao invés de cortar a imagem, vamos extrair detalhes da imagem completa automaticamente e utilizar essas características como variáveis preditoras num modelo de regressão. Chamaremos essa abordagem de *força bruta*.

### Aprendizado estatístico

#### Aprendizado supervisionado

As definições seguem a mesma terminologia de Cabannes (XXX). Nosso objetivo é obter uma função $f \in \mathcal{Y}^\mathcal{X}$ entre um espaço de entrada $\mathcal X$ e um espaço de saída $\mathcal{Y}$.

Definimos também a função de distribuição conjunta $\rho \in \Delta_{\mathcal X \times \mathcal Y}$ sobre $\mathcal X \times \mathcal Y$. Essa função nem sempre é apresentada em outros contextos, mas será útil para estudar os modelos fracamente supervisionados.

Finalmente, definimos uma função de perda $\ell \in \mathbb R^{\mathcal Y \times \mathcal Y}$, que minimiza o risco

$$
\mathcal R(f;\rho) = \mathbb E_{(X,Y)\sim\rho}[\ell(f(X),Y)]
$$

Ou seja, o risco é a o risco geral, definido como o valor esperado da função de perda sob $\rho$ para os valores possíveis de $X$ e $Y$.

#### Aprendizado fracamente supervisionado

O aprendizado fracamente supervisionado pode ser dividido em três tipos principais. A supervisão com erros, a supervisão com rótulos incompletos e a supervisão de grupos de observações. O caso do Captcha pode ser entendido como aprendizado fracamente supervisionado com rótulos incompletos, já que uma parte da base pode ser anotada (supomos que sem erros) e uma parte da base é a resposta do oráculo indicando uma lista de rótulos possíveis que incluem o correto.

Formalmente, o aprendizado fracamente supervisionado é definido como uma generalização do aprendizado totalmente supervisionado, como mostrado em seguida.

### Redes neurais

A abordagem discutida ao longo da tese utiliza redes neurais convolucionais. Para explicar o funcionamento dessa técnica, vamos primeiro apresentar definições para redes neurais e para a operação de convolução. Em seguida, vamos juntar os dois conceitos para construir o modelo utilizado nos Captchas.

Uma rede neural pode ser entendida como uma extensão de modelos lineares generalizados com a adição de uma arquitetura aos componentes do modelo. Para mostrar esse conceito, vamos partir da definição de um modelo regressão logística até construir uma rede neural com camadas ocultas.

#### Regressão logística

O modelo linear generalizado é composto por três elementos: componente aleatório, componente sistemático e função de ligação.

O componente aleatório é uma variável aleatória com distribuição pertencente à família exponencial, que dá origem à verossimilhança do modelo. O componente sistemático é uma combinação linear das variáveis preditoras com um vetor de parâmetros. A função de ligação é uma operação que leva a componente sistemática no valor esperado da componente aleatória. Uma forma comum de definir a ligação é propondo uma função com domínio nos números reais e contradomínio igual ao suporte do componente aleatório. Dessa forma, não é necessário impor restrições aos parâmetros da componente sistemática para que os valores ajustados variem na mesma faixa que o componente aleatório.

No exemplo da regressão logística, o componente aleatório tem distribuição Bernoulli com média $\mu$. O componente sistemático é a combinação linear $\mathbf X \boldsymbol \beta$ e a função de ligação é a inversa de

$$
g(\mu) = \log\left(\frac{\mu}{1-\mu}\right)
$$

A partir de uma amostra $y_1, \dots, y_n$ e observando que $\mu_i = g^{-1}(\mathbf X_i\boldsymbol\beta)$, a verossimilhança do modelo é dada por

$$
\mathcal L(\boldsymbol \beta|\mathbf y) = \prod_{i=1}^n f(y_i|\boldsymbol\beta) = \prod_{i=1}^n\mu_i^{y_i}(1-\mu_i)^{1-y_i}
$$

A log-verossimilhança é dada por

$$
l(\boldsymbol \beta|\mathbf y) = \sum_{i=1}^n y_i\log(\mu_i) + (1-y_i)\log(1-\mu_i)
$$

Uma forma útil de olhar para a verossimilhança é a partir da \textit{função desvio}, dada por

$$
D(\mathbf y|\boldsymbol \beta) = l(\mathbf y|\mathbf y) - l(\boldsymbol \beta|\mathbf y),
$$

onde $l(\mathbf y|\mathbf y)$ é a verossimilhança do modelo saturado, ou seja, calculada com $\mathbf y$ no lugar de $\boldsymbol \mu$. A partir de um modelo ajustado, a função desvio pode ser interpretada como a distância entre a verossimilhança do modelo ajustado e a verossimilhança do modelo com um parâmetro para cada observação.

Uma propriedade interessante da função desvio é que ela equivale à divergência de Kullback-Leibler. Por exemplo, para duas variáveis aleatórias com distribuição Bernoulli de parâmetros $p$ e $q$, respectivamente, a divergência de Kullback-Leibler é dada por

$$
D_{KL}(p||q) = p\log\left(\frac p q\right) + (1-p)\log\left(\frac{1-p}{1-q}\right)
$$

É fácil ver que

$$
\begin{aligned}
D(\mathbf y|{ \boldsymbol \beta}) &= \sum_{i=1}^n y_i\log(y_i) + (1-y_i)\log(1-y_i) - \sum_{i=1}^n y_i\log(\mu_i) + (1-y_i)\log(1-\mu_i) \\
&=\sum_{i=1}^ny_i\log\left(\frac{y_i}{\mu_i}\right) + (1-y_i)\log\left(\frac{1-y_i}{1-\mu_i}\right) \\
&= \sum_{i=1}^n D_{KL}(y_i||\mu_i) \\
&= D_{KL}(\mathbf y||{\boldsymbol\mu}).
\end{aligned}
$$

Outra propriedade interessante é que o desvio identifica unicamente a verossimilhança do modelo. De fato, podemos reformular a definição do modelo linear generalizado a partir da especificação do desvio ou da divergência de Kullback-Leibler no lugar do componente aleatório. Essa propriedade será útil na comparação com redes neurais.

Os estimadores de máxima verossimilhança de $\boldsymbol \beta$ são os mesmos que minimizam a função desvio. Graças à concavidade da divergência de Kullback-Leibler, Isso pode ser feito igualando os componentes do gradiente do desvio a zero e isolando os valores de $\boldsymbol \beta$:

$$
\nabla_{\boldsymbol \beta} D(\mathbf y|{ \boldsymbol \beta}) = \mathbf 0
$$

Como não é possível realizar essa operação analiticamente, utilizamos métodos iterativos. Existem dois principais métodos iterativos concorrentes: a descida de gradiente e o método de Newton-Raphson. No paradigma de modelos lineares generalizados, o método de Newton-Raphson é mais comum pois i) ele utiliza a segunda derivada e converge mais rápido que o método da descida de gradiente, que utiliza somente a primeira e ii) é possível demonstrar que ele equivale à aplicação iterada de *mínimos quadrados ponderados*, o que facilita significativamente a implementação da solução. No paradigma de redes neurais, a descida de gradiente é mais comum por conta das vantagens \textit{backpropagation}, que veremos na próxima subseção.

Em resumo, podemos concluir que

```{=tex}
\begin{enumerate}
    \item Um modelo linear generalizado pode ser definido por três componentes: a divergência de Kullback-Leibler, o preditor linear e a função de ligação.
    \item A estimação dos parâmetros do modelo é realizada via descida de gradiente ou Newton-Raphson.
\end{enumerate}
```
Em seguida, veremos que a rede neural aparece quando utilizamos o componente sistemático e a função de ligação várias vezes.

#### Extensão para redes neurais

Uma forma de estender o modelo linear generalizado é considerando que o resultado da função de ligação aplicada ao componente sistemático é uma nova covariável $z$. Assim, temos

$$
\begin{aligned}
\mathbf z &= g^{-1}(\mathbf X \boldsymbol \beta)\\
\boldsymbol\mu &= g^{-1}(\alpha_2\mathbf 1 + \beta_2 \mathbf z) = g^{-1}([\mathbf 1\;\mathbf z]\boldsymbol\beta_2),
\end{aligned}
$$

em que $\boldsymbol\beta_2 = [\alpha_2\;\beta_2]^{\top}$. Agora, podemos aumentar o número de covariáveis $\mathbf z$ para $k$ covariáveis, de modo que

$$
\begin{aligned}
\mathbf z_j &= g^{-1}(\mathbf X \boldsymbol \beta_1^j)\\
\boldsymbol\mu &= g^{-1}(\mathbf Z\boldsymbol\beta_2),
\end{aligned}
$$

onde $\mathbf Z = [\mathbf 1\;\mathbf z_1\;\dots\;\mathbf z_k]$. O modelo especificado dessa forma também é chamado de \textit{multilayer perceptron}, ou MLP.

Mesmo com essa mudança, função desvio permanece a mesma, já que construída a partir de $\boldsymbol \mu$. A única diferença é que agora ela é uma função de $\boldsymbol \beta_1^j$, $j=1,\dots,k$ e $\beta_2$. O ajuste do modelo é realizado da mesma forma:

$$
\nabla_{\{\boldsymbol \beta_1^1, \dots,\boldsymbol \beta_1^k,\boldsymbol \beta_2\}} D(\mathbf y|{ \boldsymbol \beta_1^1, \dots,\boldsymbol \beta_1^k,\boldsymbol \beta_2}) = \mathbf 0
$$

A vantagem dessa extensão é que adicionamos não linearidade ao modelo. Isso nos permite modelar relações mais complexas entre as preditoras e a resposta, o que pode resultar em melhores predições. De fato, é possível demonstrar que uma rede neural com uma camada oculta pode estima qualquer função contínua entre $\mathbf X$ e $\mathbf y$. A desvantagem é que a estimação via Newton-Raphson é complicada de calcular.

É nesse momento que aparecem as vantagens da descida de gradiente. Primeiro, defina $\boldsymbol \beta = \{\boldsymbol \beta_1^1, \dots,\boldsymbol \beta_1^k,\boldsymbol \beta_2\}$. Utilizando a regra da cadeia, a derivada parcial da função desvio em relação a $\beta_{1,l}^{j}$ é dado por

$$
\frac{\partial D(\mathbf y|\boldsymbol\beta)}{\partial \beta_{1,l}^{j}} = \sum_{i=1}^n\frac{\partial D(\mathbf y|\boldsymbol\beta)}{\partial z_{j,i}} \frac{\partial z_{j,i}}{\partial \beta_{1,l}^{j}} .
$$

As derivadas em relação aos elementos de $\boldsymbol \beta_2$ ocorrem diretamente, como na especificação em apenas um nível. Todas essas derivadas são fáceis de calcular e têm forma analítica definida. A aplicação da regra da cadeia de forma iterada nesse contexto é chamada de \textit{backpropagation}.

#### Sinônimos e generalizações

A literatura de redes neurais costuma trocar o nome função de ligação por *ativação*. Isso ocorre por motivos históricos, já que as redes neurais foram inicialmente inspiradas na ativação de sinapses de neurônios. No contexto de redes neurais, o objetivo da função de ativação não é, necessariamente, modificar a faixa de variação do contradomínio, pois o resultado após a função pode ser uma nova covariável. Isso sugere a existência de certa liberdade na escolha de ativações. A única restrição é que a função de ativação deve ser não linear, pois, se fosse linear, a aplicação de várias camadas de funções resultaria numa única combinação linear. As ativações mais populares são aquelas que têm derivadas simples.

Já a verossimilhança ou o desvio são substituídos por uma *função de perda*. A natureza probabilística do modelo é considerada indiretamente através da função desvio, como vimos anteriormente. No entanto, ao invés de trabalhar com o desvio, os pesquisadores de redes neurais definem genericamente uma função de perda que mensura uma discrepância entre os valores observados e estimados. Uma escolha razoável de função de perda é a própria divergência de Kullback-Leibler, calculada com base no suporte da variável resposta, gerando a função desvio. No entanto, dependendo da aplicação, podemos escolher outras perdas, que podem gerar distribuições de probabilidades sem formato analítico específico.

Por último, a aplicação de camadas de não-linearidades podem ser representadas através de um grafo direcionado acíclico. Essa representação é vantajosa por dois motivos. O primeiro é que a aplicação facilita a especificação e entendimento do modelo e seus parâmetros, que podem ficar com notação carregada na especificação por fórmulas matemáticas. A segunda é que é possível utilizar conhecimentos de teoria dos grafos para aumentar a eficiência dos algoritmos. Por exemplo, é possível aproveitar parte dos cálculos do \textit{backpropagation} na obtenção das derivadas parciais da função de perda abadi2016tensorflow (XXX).

Em resumo, podemos concluir que

```{=tex}
\begin{enumerate}
    \item Uma rede neural é uma extensão de modelos lineares generalizados que aplica combinações lineares e funções de ligação de forma iterada.
    \item A estimação dos parâmetros é realizada por descida de gradiente, explorando as vantagens do \textit{backpropagation}.
    \item Funções de ligação são chamadas de funções de ativação.
    \item A função desvio é substituída por funções de perda mais gerais.
    \item A aplicação iterada de operações pode ser representada por um grafo direcionado acíclico.
\end{enumerate}
```
Existem diversas formas de definir, desenhar e apresentar os conceitos básicos de redes neurais e a descida de gradiente. As melhores são apresentadas em blogs, vídeos e aplicativos, onde as operações são apresentadas de forma interativa. O racional apresentado nesse texto buscou mostrar a relação intrínseca entre a regressão logística e as redes neurais.

#### A operação de convolução

Convolução em imagens é uma operação usada nas áreas de \textit{visão computacional} e \textit{processamento de sinais}. Ela é utilizada para detectar padrões e aplicar filtros em imagens. Na prática, o que ela faz é calcular um novo valor para um pixel na posição $(i,j)$ de uma imagem com base nos valores dos pixels da vizinhança.

Uma forma organizada de fazer essa soma ponderada é criando uma matriz de pesos. Com ela, não é necessário procurar os pontos da vizinhança. Para cada ponto $(i,j)$, obtemos a matriz de vizinhança, multiplicamos pontualmente pela matriz de pesos e somamos os valores resultantes. Chamaremos essa matriz de pesos de \textbf{kernel}.

Considere

$$
K = \left[\begin{array}{rrr}-1&-1&-1\\0&0&0\\1&1&1\end{array}\right]
$$

e a seguinte imagem:

IMAGEM

Tome por exemplo o ponto $(i,j) = (12,16)$. A vizinhança 3x3 em torno desse ponto é dada por

$$
P_{i,j} = \left[\begin{array}{rrr}
0.98 & 0.53 & 0.79 \\ 
0.97 & 0.99 & 1.00 \\ 
0.98 & 1.00 & 1.00 
\end{array}\right]
$$

A operação de convolução é feita da seguinte forma:

$$
\begin{aligned}
(P_{12,16} *K )_{12,16}
&= k_{1,1}p_{11,15} + k_{1,2}p_{11,16} + k_{1,3}p_{11,17} + \\
&+ k_{2,1}p_{12,15} + k_{2,2}p_{12,16} + k_{2,3}p_{12,17} + \\
&+ k_{3,1}p_{13,15} + k_{3,2}p_{13,16} + k_{3,3}p_{13,17}
\end{aligned}
$$

Esse é o valor a ser colocado no ponto $(i,j)$. Isso funciona em todos os pontos que não estão na borda da imagem.

Existem duas formas de trabalhar com as bordas da imagem. A primeira é preenchendo as bordas com zeros, de forma a considerar apenas os pontos da imagem. A segunda é descartar os pontos da borda e retornar uma imagem menor, contendo somente os pixels em que foi possível aplicar todo o kernel.

No nosso caso, o resultado da convolução fica como na Figura XXX. Essa matriz não foi escolhida por acaso. Ela serve para destacar padrões horizontais da imagem. Como a primeira linha é formada por $-1$ e a última é formada por $1$, a matriz fica com valor alto se a parte de cima do pixel for preta e a parte de baixo for branca ($\text{grande} * 1 + \text{pequeno} * (-1)$). A parte destacada da imagem acabou sendo os olhos (pois temos maior concentração de pixels pretos ali), além das extremidades superior e inferior do rosto.

IMAGEM

Aplicando o kernel vertical

$$
K = \left[\begin{array}{rrr}-1&0&1\\-1&0&1\\-1&0&1\end{array}\right],
$$

a parte destacada do rosto são as extremidades dos lados:

IMAGEM

```{r, out.width="30%", echo=FALSE, no.mar=TRUE, eval=FALSE, fig.align="center"}
library(magrittr)
"assets/img/emoji3.png" %>% 
  magick::image_read() %>% 
  plot()
```

```{r emoji-horiz, no.mar=TRUE, out.width="30%", fig.cap="Figura após aplicação de convolução.", echo=FALSE, eval=FALSE, fig.align="center"}
kern_horizontal <- matrix(c(-1,-1,-1,0,0,0,1,1,1), ncol = 3, byrow = TRUE)
convolve <- function(img, kern) {
  # monta a bordinha na imagem. A borda deve ter (tamanho kernel) / 2,
  # de tamanho, arredondando para baixo
  pad <- floor(dim(kern)[1] / 2)
  img_pad <- matrix(0, nrow = nrow(img) + 2 * pad, ncol = ncol(img) + 2 * pad)
  img_pad[pad + 1:nrow(img), pad + 1:ncol(img)] <- img[,,1]
  # aplica a convolução nos pontos da imagem
  for (i in seq_len(nrow(img))) {
    for (j in seq_len(ncol(img))) {
      img[i, j, 1] <- sum(img_pad[i + 0:(2 * pad), j + 0:(2 * pad)] * kern)
    }
  }
  img[,,2] <- img[,,3] <- img[,,1]
  img
}
"assets/img/emoji3.png" %>% 
  decryptr:::load_image() %>% 
  convolve(kern_horizontal) %>% 
  magick::image_read() %>% 
  plot()
```

```{r, no.mar=TRUE, out.width="30%", echo=FALSE, eval=FALSE, fig.align="center"}
kern_vertical <- rbind(c(-1, 0, 1),
                       c(-1, 0, 1),
                       c(-1, 0, 1))
"assets/img/emoji3.png" %>% 
  decryptr:::load_image() %>% 
  convolve(kern_vertical) %>% 
  magick::image_read() %>% 
  plot()
```

A aplicação de convoluções em CAPTCHAs é direta. Nesse caso, vamos adicionar uma constante numérica ao resuldado da convolução. Isso pode auxiliar na visualização, pois controlamos os valores que ficam dentro do intervalo $[0,1]$. Mais adiante veremos que esse será o intercepto da regressão.

Vamos partir do CAPTCHA da RFB abaixo

```{r, fig.height=1, fig.width=3.6, no.mar=TRUE, echo=FALSE, eval=FALSE, fig.align="center"}
arq <- "assets/img/captcha41367a06c5a.png"
op <- graphics::par(mar = rep(0, 4))
arq %>% 
  decryptr:::load_image() %>% 
  magick::image_read() %>% 
  plot()
```

```{r, echo=FALSE}
add_bias <- function (x, b) x + b
```

Esse é o resultado de adicionar o kernel vertical e bias de `0.6`.

```{r, fig.height=1, fig.width=3.6, no.mar=TRUE, echo=FALSE, eval=FALSE, fig.align="center"}
op <- graphics::par(mar = rep(0, 4))
arq %>% 
  decryptr:::load_image() %>% 
  convolve(kern_vertical) %>% 
  add_bias(.6) %>% 
  magick::image_read() %>% 
  plot()
```

Em seguida observamos o kernel horizontal. Note que identificamos padrões das linhas horizontais que tentam atrapalhar a visão das letras.

```{r, fig.height=1, fig.width=3.6, no.mar=TRUE, echo=FALSE, eval=FALSE, fig.align="center"}
op <- graphics::par(mar = rep(0, 4))
arq %>% 
  decryptr:::load_image() %>% 
  convolve(kern_horizontal) %>% 
  add_bias(.6) %>% 
  magick::image_read() %>% 
  plot()
```

#### Redes neurais convolucionais

Considere uma observação de uma imagem com 2x2 pixels abaixo. Note que se o interesse for utilizar essa matriz numa regressão logística, teríamos uma linha de nossa base de dados, com nove colunas. Ou seja, a regressão teria nove parâmetros associados.

$$
P = \left[\begin{array}{rrr}
p_{11} & p_{12} & p_{13} \\ 
p_{21} & p_{22} & p_{23} \\
p_{31} & p_{32} & p_{33}
\end{array}\right]
$$

Considere agora o kernel $W$, também 3x3:

$$
K = \left[\begin{array}{rrr}
k_{11} & k_{12} & k_{13} \\ 
k_{21} & k_{22} & k_{23} \\
k_{31} & k_{32} & k_{33}
\end{array}\right]
$$

A operação convolução resulta numa nova matriz 3x3, em que cada elemento é uma combinação linear de elementos de $P$ e $K$. De fato, é possível mostrar que o resultado da convolução é o resultado de uma multiplicação de matrizes obtida através da \textit{matriz circulante} de $K$ gray2006toeplitz (XXX). Ou seja, nesse caso, estamos fazendo uma nova regressão logística, mas com os valores dos dados modificados.

Se, ao invés disso, considerarmos a matriz 2x2,

$$
K = \left[\begin{array}{rr}
k_{11} & k_{12}\\ 
k_{21} & k_{22}
\end{array}\right]
$$

estamos na prática reduzindo o problema de regressão logística para apenas quatro parâmetros.

Também vamos introduzir uma função chamada \textbf{ReLu}. ReLu significa \textit{Restricted Linear Unit} e é uma função que zera tudo o que é negativo e mantém tudo aquilo que é positivo inalterado. Ou seja,

$$
ReLu(x) = \frac{x + |x|}{2}
$$

ReLu não é útil para visualização da imagem, pois a substituição de valores negativos por zero já é feita automaticamente. No entanto, podemos aplicar várias convoluções iteradamente e separá-las por aplicações da função ReLu. Como a função ReLu é não linear, essa iteração gera resultados que não seriam possíveis de obter somente com aplicações da operação convolução.

Na prática, o que queremos é treinar os valores do kernel aplicado, buscando obter imagens transformadas que aumentem o poder preditivo. Nesse sentido, a aplicação de convoluções, soma de constantes e ReLu são as operações que substituem a multiplicação de matrizes, adição de intercepto e aplicação da função de ligação na regressão logística, respectivamente. Ou seja, uma rede neural convolucional é apenas uma forma diferente de implementar os conceitos.

O modelo força-bruta é uma adaptação do clássico modelo LeNet-5 lecun2015lenet (XXX). Esse modelo aplica convolução 3 vezes consecutivas, adicionando o viés e a função ReLu em cada nível. Após cada convolução, também aplicamos uma operação chamada \textit{max pooling}, que reduz a resolução da imagem, tomando o valor máximo da vizinhança de cada ponto. Após a aplicação das convoluções, as imagens são remodeladas no formato retangular padrão (uma linha por imagem) e aplicamos duas camadas de redes neurais comuns, como vimos anteriormente.

Após a realização de todas as operações, os números resultantes não estão entre zero e um. Por isso, aplicamos a ativação \textit{softmax}, que é a generalização da ativação logística, mas para uma resposta com vários resultados possíveis

$$
softmax(x_i) = \frac{e^{x_i}}{\sum_ie^{x_i}}
$$

Em resumo, as operações que realizamos na rede neural convolucional são

```{=tex}
\begin{enumerate}
    \item Tomar o input inicial (imagem).
    \item Multiplicar (convoluir) por matrizes de pesos $W$.
    \item Adicionar um viés (ou intercepto) $b$.
    \item Aplicar uma função de ligação (ou ativação), por exemplo ReLu.
    \item Reduzir a resolução do resultado.
    \item Voltar para 2 várias vezes.
    \item Tomar os pesos finais e normalizar (usando a operação \textit{softmax}) para obter probabilidades dos resultados.
\end{enumerate}
```
#### Arquitetura de redes neurais

### Ligando os conceitos

<!-- Obs: talvez essa seção não seja necessária -->

A obtenção de uma função $g$ capaz de mapear $\mathbf y$ a partir de uma nova imagem $\mathbf X$ depende de uma amostra de imagens $\mathbf X_1, \dots, \mathbf X_S$, corretamente classificadas através do vetor $\mathbf y_1, \dots, \mathbf y_S$. A tarefa é, portanto, obter uma estimativa $\hat g$ para a função $g$ que minimiza

$$
L(\hat g(\mathbf X), \mathbf y) = \mathbb I(g(\mathbf X) \neq \mathbf y)
$$

em que $\mathbb I(g(\mathbf X) \neq \mathbf y)$ indica se $g(\mathbf X)$ difere do que é observado em $\mathbf y$. Isto é, pretende-se encontrar uma função que minimize a taxa de classificação incorreta das imagens que descrevem os textos dos Captchas.

<!-- ---------------------------------------------------------------------- -->

## Dados

Neste capítulo, descrevemos em detalhes como foi a obtenção dos dados para a realização da pesquisa. Como comentado anteriormente, a base foi construída do zero para os fins do projeto, sendo uma parte significativa dos esforços para obtenção dos achados.

No total, foram construídas bases de dados de dez Captchas que estavam disponíveis publicamente no momento da realização da pesquisa. Os Captchas foram revisados pela última vez no dia 14/02/2022, para verificar se ainda estavam ativos.

### Escolha dos captchas analisados

Para selecionar os Captchas, adotamos alguns critérios objetivos. Os critérios foram:

1.  O site acessado é de um serviço público (governo federal, tribunais, etc).
2.  Trata-se de um Captcha contendo letras (A a Z) e números (0 a 9) em uma imagem com extensão jpeg ou png.
3.  O comprimento do Captcha é fixo, ou seja, dois Captchas da mesma origem devem ter sempre o mesmo comprimento.

A primeira restrição para escolha dos Captchas é de ordem principiológica. Um serviço público não deveria restringir o acesso aos dados para robôs. Como já discutido anteriormente, nesses casos, a existência do Captcha não tem como finalidade dar maior segurança ao serviço prestado, mas sim limitar o acesso aos servidores por robôs.

As restrições 2 e 3 foram escolhidas com o objetivo de facilitar as simulações para obtenção dos resultados. Em princípio, nada impede que os modelos desenvolvidos trabalhem com outros tipos de rótulos, desde que exista uma lista prévia de rótulos. Além disso, é possível realizar adaptações no pré-processamento base de dados para lidar com diferentes comprimentos de Captchas.

A Tabela \@ref(tab:lista-captcha) mostra os Captchas trabalhados. A informação de limite de chutes é importante para a implementação do oráculo, detalhado a seguir.

```{r lista-captcha}

head(cars) |> 
  knitr::kable(
    caption = "Lista de captchas analisados."
  )

```

O oráculo é o nome que escolhemos para a possibilidade de checar, de forma automática, se uma predição do modelo foi bem ou mal sucedida. Como um Captcha é um teste de Turing inverso, por definição ele é obrigado a mencionar se uma predição está correta: se a predição foi correta, a página de interesse é acessada; se a predição está incorreta, o site envia uma mensagem de erro.

Para implementar um oráculo em uma linguagem de programação, é necessário seguir os seguintes passos:

1.  Acessar a página do site de interesse
2.  Preencher o formulário de pesquisa com a informação a ser consultada. Por exemplo, no site da RFB, a informação é o CNPJ da empresa a ser consultada. Em um site de tribunal, a informação é um número identificador de processo.
3.  Baixar o Captcha da busca.
4.  Aplicar o modelo no Captcha baixado (ou classificar a imagem manualmente) para obter a predição.
5.  Submeter a consulta no site, informando a predição.
6.  Verificar o resultado. Se acessou a página desejada, a predição está correta. Caso contrário, a predição está incorreta.

Outra oportunidade que o oráculo permite em parte dos casos é a possibilidade de testar mais de uma predição. Sites com essa caracteística permitem que a pessoa ou robô teste mais de uma predição caso o Captcha tenha fracassado. Como é possível observar na Tabela \@ref(tab:lista-captcha), dos 10 Captchas trabalhados, 7 permitem a realização desses testes.

Em teoria, a possibilidade de testar vários rótulos para o mesmo Captcha implica na possibilidade teórica de resolver um Captcha por força bruta. Bastaria testar todos os rótulos possíveis para acessar a página de interesse. Na prática, no entanto, essa estratégia não funciona, já que a quantidade de rótulos possíveis é muito grande para testar no site, seja por demorar muito tempo ou pelo site forçar a troca de Captcha após a passagem de determinado tempo ou quantidade de tentativas.

> Lista e caracterização dos captchas

Além dos Captchas de sites, também consideramos imagens geradas artificialmente para rodar os modelos. O motivo de criar Captchas artificiais é a facilidade de rodar modelos e simulações, já que nos casos reais é necessário ter acesso à internet e também construir bases de dados de cada Captcha.

Desenvolvemos duas alternativas para o Captcha gerado. O primeiro, chamado MNIST-Captcha, é simplesmente uma adaptação da conhecida base MNIST para ficar no formato de um Captcha. A partir da escolha do comprimento e dos caracteres que fazem parte da imagem, o gerador simplesmente faz uma amostra aleatória da base do MNIST e compõe as imagens horizontalmente.

A Figura \@ref(fig:captcha-mnist) mostra um exemplo do Captcha gerado a partir da base MNIST. No exemplo, o comprimento escolhido para o Captcha foi de 4 valores.

```{r captcha-mnist, fig.cap="Exemplo de MNIST-Captcha", eval=FALSE}

path_mnist <- "~/Documents/jtrecenti/captchaDownload/data-raw/mnist/img_individual"
x <- captchaDownload:::captcha_generate_mnist(".", path_mnist)
plot(captcha::read_captcha(x))

```

O problema do MNIST-Captcha é que a base de dados original é finita. Apesar de possuir por volta de 60 mil observações e de um Captcha crescer em ordem exponencial, o MNIST-Captcha pode gerar Captchas repetidos. Além disso, é necessário tomar cuidado com as bases de treino e teste, já que os elementos de teste não poderiam fazer parte de nenhuma observação de treino.

Por esse motivo, criamos um Captcha interamente gerado por programação, chamado R-Captcha. O Captcha é gerado utilizando a ferramenta ImageMagick, com a possibilidade de customizar diversos parâmetros, como

-   Quais caracteres usar na imagem
-   O comprimento do Captcha
-   Dimensões da imagem
-   Probabilidade de rotação da imagem
-   Probabilidade de adicionar um risco entre as letras
-   Probabilidade de adicionar uma borda nas letras
-   Probabilidade de adicionar uma caixa (retângulo) em torno das letras
-   Probabilidade de adicionar um ruído branco no fundo da imagem
-   Probabilidade de adicionar efeitos de tinta óleo e implosão

```{r, captcha-r}
plot(captcha::captcha_generate()$image)
```

Por ser uma versão mais flexível e completa, optamos por trabalhar principalmente com o R-Captcha nas simulações. O MNIST-Captcha foi implementado mas não foi utilizado nas simulações.

> Repositório de dados

Os Captchas foram classificados com o procedimento que chamamos de semi-automático, definido a seguir. No pacote `{captchaDownload}`, foram desenvolvidas ferramentas para baixar e organizar cada Captcha, utilizando o oráculo para garantir que as imagens eram corretamente classificadas.

Cada Captcha teve as primeiras 100 observações classificadas manualmente. Isso foi feito a partir do próprio RStudio, utilizando a ferramenta de classificação manual do pacote `{captcha}`.

A partir das classificações iniciais, um modelo foi ajustado com a quantidade de observações disponível. Esse passo também foi feito a partir do pacote `{captcha}`, que cria um projeto de classificação para um Captcha específico.

O modelo, então, foi utilizado como uma ferramenta para otimizar a classificação manual, funcionando da seguinte forma. Primeiro, o modelo tenta realizar a predição automaticamente e o oráculo avisa se a predição está correta ou não. Se estiver incorreto, e o site aceitar várias tentativas, o modelo tenta novamente, mas com uma segunda alternativa de predição, definida por uma heurística, definida no Capítulo \@ref(modelo). Caso o site não aceite várias tentativas ou o modelo não consiga acertar o Captcha em $N$ tentativas (que arbitramos como dez), a imagem do Captcha aparecerá para classificação manual.

Com o procedimento destacado acima, é criada uma nova base de dados, que por sua vez é utilizada para ajustar um novo modelo. O modelo, atualizado, é utilizado para classificar novos Captchas, e assim por diante, até que o modelo ajustado alcance uma acurácia razoável, que arbitramos em 80%. Com isso, finalizamos o procedimento de classificação.

O único problema do procedimento de classificação diz respeito aos Captchas que não aceitam várias tentativas. Nesses casos, não é possível verificar com certeza absoluta que um caso classificado manualmente (após a tentativa do modelo) foi classificado corretamente, já que a classificação manual seria a segunda tentativa. No entanto, esse problema aparece somente em três Captchas (`cadesp`, `jucesp` e `trf5`). A classificação manual dos 100 primeiros Captchas, no entanto, mostrou que pelo menos 95% dos Captchas foram classificados corretamente quando classificados manualmente. Supomos que a proporção máxima de 5% de erro é negligenciável considerando que a maior parte das bases de dados foi construída com verificação do oráculo.

Para este trabalho, desenvolvemos uma técnica inovadora para resolver Captchas sem a necessidade de *feedback* humano. A solução envolve avanços em duas direções: engenharia e modelagem.

### Construção dos dados

Na parte de engenharia, desenvolvemos uma técnica para capturar e anotar feedbacks automatizados do oráculo no preenchimento de Captchas. A técnica consiste em três passos:

1.  Desenvolver um robô que acessa o site desejado e tenta acessar uma informação que exige preenchimento de Captcha.
2.  A partir de um modelo estatístico inicial, o robô tenta preencher o Captcha automaticamente, submetendo para avaliação do site.
3.  Se o Captcha for verificado pelo site como correto, anotamos o caminho da imagem com o valor "1". Se estiver incorreto, anotamos o caminho da imagem com o valor "0".

O procedimento descrito pode ser reproduzindo indefinidamente. Isso significa que podemos criar uma base de dados virtualmente infinita de Captchas rotulados, com a informação adicional do rótulo estar correto ou incorreto. Fizemos isso para todos os Captchas presentes em nossa base de dados.

O problema do uso de oráculos é que a informação adicional recebida quando o modelo erra é **incompleta**. A única informação nova que temos é que o rótulo testado está incorreto, dentre todos os rótulos possíveis daquela imagem. Como temos uma grande quantidade de rótulos possíveis em um Captcha, muitas vezes na ordem de milhões, o *feedback* do oráculo pode ser considerado fraco.

Uma possível abordagem para lidar com o segundo problema seria simplesmente descartar os Captchas classificados incorretamente. Podemos criar uma base de dados (virtualmente infinita) somente com os rótulos corretos e ajustar um novo modelo. Essa abordagem, no entanto, tem sérios problemas, já que considera somente os casos em que o classificador já funciona bem. Nosso objetivo é melhorar o modelo justamente nos casos em que o oráculo acusa erros.

### Análise descritiva

Os resultados empíricos foram divididos em dois testes. Primeiro, separamos uma amostra rotulada para verificar o quanto a heurística recuperava os valores corretos, a partir da predição de um modelo inicial. Depois, verificamos o ganho efetivo na acurácia do modelo alimentado com a base de dados aumentada, descrita na Seção \@ref(simulacoes).

Para o primeiro teste, adotamos o seguinte procedimento. Para cada Captcha, selecionamos bases de treino iniciais que resultaram em acurácias de 40%, 60% e 80% após o ajuste do modelo de redes neurais convolucionais. Em seguida, aplicamos a heurística nos casos da base de teste em que o modelo errou. Finalmente, calculamos o percentual de recuperação dos resultados pela heurística.

A parte do ajuste do modelo de redes neurais convolucionais merece alguns comentários adicionais. Por um lado, é importante que o modelo esteja bem ajustado, para que o erro do modelo seja fruto somente da quantidade de observações e não um problema de sub ajuste. Por outro lado, cada tamanho de base pode estar ligada a diferentes hiperparâmetros, e não existe uma forma de garantir que os melhores hiperparâmetros foram selecionados.

@goodfellow2014 menciona que, para realizar comparações de modelos, as técnicas de regularização, especialmente aumentação de dados, devem ser padronizadas. Por isso, optamos por manter a mesma grade de hiperparâmetros em todos os modelos. Especificamente, consideramos na grade as quantidades:

-   Multiplicador da quantidade de filtros convolucionais.
-   Quantidade de filtros na primeira camada densa.
-   Dropout.

Para diferentes modelos, como AC-GAN, o procedimento seria o mesmo. Bastaria fixar os hiperparâmetros e rodar todos os modelos.

A Tabela \@ref(tab:) mostra os resultados da análise. É possível verificar que a heurística X apresenta os melhores resultados, independentemente do Captcha ou da capacidade do modelo inicial.

A Figura \@ref(fig:) mostra os mesmos resultados de forma visual e resumida. É possível notar que a proporção de casos recuperados não aumenta linearmente

Em seguida, passamos para a segunda etapa do procedimento. Nesta etapa, adicionamos a base construída pelo oráculo e modificada pela heurística à base de treino inicial. Como base de teste, utilizamos um conjunto de dados novo, que não foi utilizado em nenhum procedimento anterior, para garantir que não há contaminação.

<!-- ---------------------------------------------------------------------- -->

## Simulações {#simulacoes}

Para verificar o poder do uso do oráculo para o aprendizado do modelo, recorremos a uma série de simulações. As simulações foram organizadas em três passos: modelo inicial, dados e modelo final. Os passos foram descritos em maior detalhe a seguir.

### Primeiro passo: modelo inicial

A simulação do modelo inicial teve como objetivo obter modelos preditivos de Captchas com acurácias distintas. O modelo inicial seria usado, então, para baixar dados diretamente do site usando o oráculo e, por fim, ajustar um modelo final com os novos dados provenientes do oráculo.

Construímos os modelos iniciais em dois passos. O primeiro foi montar a base de dados completa, suficiente para ajustar um modelo com alta acurácia, que arbitramos em 80%, como descrito anteriormente. Depois, montamos 10 amostras de dados com subconjuntos das bases completas, cada uma contendo 10%, 20%, e assim por diante, até a base completa. Por exemplo: no Captcha da Jucesp, obtivemos um modelo com acurácia maior que 80% com 4000 Captchas. Fizemos então uma partição dos dados com 400 imagens (10% do total), 800 imagens (20% do total) e assim por diante, até o modelo com 4000 Captchas.

Para cada tamanho de amostra $A$, rodamos uma bateria de 27 modelos. Fizemos isso porque para diferentes quantidades de amostra, a configuração dos hiperparâmetros que resulta no melhor modelo pode ser diferente. Fizemos uma grade de hiperparâmetros considerando três informações:

-   A quantidade de unidades computacionais na primeira camada densa após as camadas convolucionais: consideramos os valores de 100, 200 e 300.
-   O valor do *dropout* aplicado às camadas densas: consideramos os valores de 10%, 30% e 50%.
-   O fator de decaimento na taxa de aprendizado a cada época: consideramos os valores de 1%, 2% e 3%.

Combinando os três valores dos três hiperparâmetros, temos um total de $27=3^3$ hiperparâmetros. Com isso, foi possível identificar, para cada tamanho de amostra $A$, o classificador $C_A$ com a melhor acurácia dentre os modelos ajustados.

No final do primeiro passo, portanto, consideramos apenas o melhor modelo para cada tamanho de amostra. É claro que os modelos encontrados por essa técnica não são, necessariamente, os melhor modelo possíveis. No entanto, como a técnica é a mesma para todos os Captchas, ganhamos a possibilidade de fazer comparações e temos uma metodologia mais transparente.

### Segundo passo: dados

O segundo passo teve como objetivo construir as bases de dados utilizando o oráculo. Primeiro, foi necessário decidir quais modelos, dentre os 10 ajustados para cada Captcha, seriam utilizados para construir novas bases. Não faria sentido, por exemplo, considerar um modelo com acurácia de 0%, já que ele não produziria nenhuma observação comparado com um modelo que chuta aleatoriamente. Também não faria sentido considerar um classificador com acurácia de 100%, já que nesse caso não há o que testar com a técnica do oráculo.

Decidimos que seria necessário considerar somente os modelos que resultaram em acurácias maiores de 1% e menores de 50%. O valor máximo foi decidido após realizar alguns testes empíricos e verificar, informalmente, que a técnica do oráculo realmente resultava em ganhos expressivos, mesmo com modelos de baixa acurácia. Concluímos então que não seria necessário testar a eficácia da técnica para classificadores com alta acurácia. Já o valor mínimo foi decidido de forma arbitrária, retirando-se os classificadores com acurácia muito baixa.

A segunda decisão a ser tomada para construção dos dados foi a quantidade de imagens que seria baixada para cada Captcha. Como temos Captchas de diferentes dificuldades, a quantidade de dados seria diferente. Optamos por baixar a quantidade de dados de forma a montar uma base de treino que contém a quantidade de observações igual ao melhor modelo daquele Captcha. Por exemplo, no TJRS, um modelo com acurácia próxima de 100% foi identificado com 2000 observações. O melhor modelo com 300 imagens (240 para treino, 60 para teste) resultou em uma acurácia de 35%. Foram, então, baixadas 1760 observações para compor o total de 2000 na base de treino. As imagens de teste do modelo inicial poderiam até ser utilizadas, mas optamos por descartar para garantir que o modelo não ficasse sobreajustado para a primeira base.

O motivo de baixar a mesma quantidade de observações que o melhor modelo inicial foi feita por dois motivos. O primeiro é que temos evidências de que é possível construir um bom modelo com essa quantidade de imagens, ainda que em um caso tenhamos informações completas, e no outro incompletas. O segundo é que isso nos permite comparar o resultado do modelo completamente anotado contra o modelo que é parcialmente anotado e com anotações incompletas provenientes do oráculo.

A terceira e última decisão tomada para baixar os dados foi a quantidade de chutes que o modelo poderia fazer, nos casos em que isso é permitido pelo site. Optamos, de forma arbitrária, por três valores: 1, que é equivalente a um site que não permite múltiplos chutes, 5 chutes e 10 chutes.

Portanto, o procedimento de coleta dos dados foi feito, para cada Captcha, da seguinte forma:

1.  Listamos todos os melhores modelos ajustados para cada tamanho de amostra.
2.  Filtramos os modelos para os que apresentavam acurácia de 5% até 50%
3.  Definimos o tamanho da base a ser obtida, com base no tamanho da base de treino utilizada no modelo e a quantidade total que se objetivou obter.
4.  Para cada quantidade de tentativas disponível (1, 5 e 10), baixamos as imagens, classificando com o valor "1" se o Captcha fosse classificado corretamente em alguma das tentativas, e com o valor "0" caso contrário.
5.  Nos casos com erros, armazenamos um arquivo de log para cada Captcha com o histórico de tentativas incorretas, que é a informação mais importante a ser passada do modelo final.

No final, obtivemos bases de dados de treino para todos os Captchas analisados, com quantidades de imagens variadas de acordo com os parâmetros definidos anteriormente, variando também pela quantidade de tentativas. A quantidade total de bases de dados geradas foi 65.

Além das bases de treino, construímos, para cada Captcha, uma base de teste. As bases de teste foram construídas completamente do zero, sem utilizar informações de bases anteriores. Para construir as bases, utilizamos a mesma técnica semi-automática definida anteriormente, usando o melhor modelo disponível para classificar a maioria das imagens e classificando manualmente em caso de falha. Em alguns casos, como TJMG e TJRS, a classificação humana quase não foi necessária, pois os classificadores obtidos apresentaram acurácia próxima de 100%.

Como o único objetivo da base de teste foi o de estimar a acurácia dos modelos finais, a quantidade de observações poderia ser arbitrada. O tamanho das bases de teste foi, então, arbitrado em 1000 imagens para todos os Captchas.

### Terceiro passo: modelo final

O modelo final foi ajustado para cada uma das 65 bases de treino disponíveis após a realização dos passos 1 e 2. Nesse caso, utilizamos o modelo proposto, que considera os erros na verossimilhança do modelo. Caso a imagem tenha sido corretamente classificada, a função de perda é calculada normalmente. Caso ela tenha sido classificada incorretamente, consideramos na verossimilhança a probabilidade de não observar nenhum dos chutes.

Exemplo. Considere um Captcha com letras e números como vocabulário e comprimento de 4 valores. Uma imagem apresenta o rótulo (correto) "zab2". O classificador do passo inicial tentou as seguintes configurações: "zab5", "sab2", "sab5", "zob2", "zob5", todas erradas. A probabilidade considerada na verossimilhança para essa imagem é, portanto:

$$
P = 1 - p(\text{zab5})- p(\text{sab2})- p(\text{sab5})- p(\text{zob2})- p(\text{zob5})
$$

Além de modificar a forma de calcular a função de perda do modelo, foi necessário testar os hiperparâmetros. Optamos por utilizar os mesmos hiperparâmetros dos modelos iniciais para manter a consistência. O único detalhe nesse ponto é que, como partimos dos parâmetros do modelo inicial, optamos por não modificar a quantidade de unidades na camada densa, variando somente os valores de *dropout* e de decaimento na taxa de aprendizado. Portanto, ajustamos 9 e não 27 modelos para cada base de dados.

No final, assim como no primeiro passo, selecionamos classificador com melhor acurácia para cada modelo. Ficamos, então, com 65 modelos no final para comparar com os modelos iniciais e estimar a efetividade do oráculo. As comparações foram feitas através de gráficos de barras, explorando o efeito do uso do oráculo para diferentes Captchas, diferentes modelos iniciais e diferentes quantidades de chutes, além de um gráfico de dispersão para relacionar as acurácias iniciais e finais.

Além do terceiro passo, fizemos alguns experimentos para verificar se, ao aplicar a técnica do oráculo iterativamente, poderíamos obter melhores resultados. Ou seja, podemos considerar os modelos obtidos no passo 3 como os modelos iniciais do passo 1, aplicar novamente o passo 2 (baixar dados) e o passo 3 (rodar modelo com os novos dados). Isso foi feito para apenas um conjunto selecionado de Captchas para verificar essa possibilidade, não fazendo parte das simulações principais deste estudo.
