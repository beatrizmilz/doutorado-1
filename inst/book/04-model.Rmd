$$\newcommand{\x}{\mathbf{x}}
\newcommand{\X}{\mathbf{X}}
\renewcommand{\s}{\mathbf{s}}
\renewcommand{\S}{\mathbf{S}}
\renewcommand{\Z}{\mathbf{Z}}
\renewcommand{\z}{\mathbf{z}}
\newcommand{\w}{\mathbf{w}}
\renewcommand{\P}{\mathbb{P}}
\renewcommand{\tt}{\boldsymbol{\theta}}$$

# Modelagem {#modelo}

Para este trabalho, desenvolvemos uma técnica inovadora para resolver Captchas sem a necessidade de *feedback* humano. A solução envolve avanços em duas direções: engenharia e modelagem.

## Construção dos dados {#construcao}

Na parte de engenharia, desenvolvemos uma técnica para capturar e anotar feedbacks automatizados do oráculo no preenchimento de Captchas. A técnica consiste em três passos:

1.  Desenvolver um robô que acessa o site desejado e tenta acessar uma informação que exige preenchimento de Captcha.
2.  A partir de um modelo estatístico inicial, o robô tenta preencher o Captcha automaticamente, submetendo para avaliação do site.
3.  Se o Captcha for verificado pelo site como correto, anotamos o caminho da imagem com o valor "1". Se estiver incorreto, anotamos o caminho da imagem com o valor "0".

O procedimento descrito pode ser reproduzindo indefinidamente. Isso significa que podemos criar uma base de dados virtualmente infinita de Captchas rotulados, com a informação adicional do rótulo estar correto ou incorreto. Fizemos isso para todos os Captchas presentes em nossa base de dados.

Um problema prático do oráculo é sua propriedade de **memória**. Em problemas reais, não é possível testar diferentes rótulos para a mesma imagem, o que inviabiliza o uso de técnicas de força bruta na resolução de Captchas.

Outro problema é que a informação adicional recebida quando o modelo erra é **incompleta**. A única informação nova que temos é que o rótulo testado está incorreto, dentre todos os rótulos possíveis daquela imagem. Como temos uma grande quantidade de rótulos possíveis em um Captcha, muitas vezes na ordem de milhões, o *feedback* do oráculo pode ser considerado fraco.

Uma possível abordagem para lidar com o segundo problema seria simplesmente descartar os Captchas classificados incorretamente. Podemos criar uma base de dados (virtualmente infinita) somente com os rótulos corretos e ajustar um novo modelo. Essa abordagem, no entanto, tem sérios problemas, já que considera somente os casos em que o classificador já funciona bem. Nosso objetivo é melhorar o modelo justamente nos casos em que o oráculo acusa erros.

Fizemos isso de duas formas.

## Modelagem usando heurísticas {#heuristica}

O fato da informação ser incompleta e fraca não significa que ela é inútil. Os Captchas que estamos trabalhando possuem várias letras geradas de forma independente, fazendo com que um classificador $g$ seja na verdade um classificador multivariado:

$$\begin{align*}
g(\X) = (g(\X)_1, g(\X)_2, \dots, g(\X)_k),
\end{align*}$$

sendo $k$ o número de letras do Captcha. Supondo que o classificador é igualmente poderoso para todas as posições das letras, temos que

$$\begin{align*}
p = \P(g(\X) = Y) = \P(g(\X)_1 = Y_1)^k = p_{1}^k
\end{align*}.$$

Seja $N$ a quantidade de acertos de $g(\X)$. Sabemos que $N\sim \text{Bin}(k, p_{1})$. Então, quando o oráculo acusa que o modelo errou, a probabilidade do modelo ter errado somente uma letra é

$$\begin{align*}
\P(\text{errei uma letra}\;|\;\text{errei}) &= \P(N=k-1|N\neq k) \\
&= \frac{(k-1) p_{1}^{k-1} (1-p_{1})}{1-p_1^k}
\end{align*}$$

A Figura \@ref(fig:probabilidades) mostra as probabilidades da equação acima graficamente, considerando $k=5$. Como vimos, é razoável admitir que um modelo inicial teria pelo menos 80% de acurácia para uma letra específica. Nessas condições, quando o oráculo dá um feedback negativo, a probabilidade do modelo ter errado somente uma letra do Captcha é próxima a 50%.

```{r probabilidades, fig.height=4, fig.width=7, fig.cap="Probabilidade do modelo ter errado somente uma letra, a partir de um feedback negativo do oráculo. Considerando um captcha de 5 letras."}
k <- 5
p <- seq(.5, .999, .001)
prob <- (k-1) * p^(k-1) * (1-p) / (1-p^k)
ggplot2::qplot(p, prob, geom = "line") +
  ggplot2::theme_minimal(12) +
  ggplot2::scale_x_continuous(labels = scales::percent) +
  ggplot2::scale_y_continuous(labels = scales::percent) +
  ggplot2::geom_hline(yintercept = 1-1/k, linetype = 2, colour = 2) +
  ggplot2::annotate("text", x = .5, y = 1-1/k, label = "Limite teórico = 1-1/k", vjust = 1.4, hjust = 0, size = 3, colour = 2) +
  ggplot2::labs(
    x = "Probabilidade do modelo acertar uma letra",
    y = "Probabilidade de ter errado somente uma letra\ndado o feedback negativo do oráculo"
  )
```

As intuições apresentadas sugerem duas possibilidades. Por um lado, podemos pensar em uma estratégia para corrigir os dados a partir do feedback do usuário e das probabilidades reportadas pelo modelo de classificação. Chamaremos uma estratégia desse tipo de *heurística*.

> Definir as heurísticas possíveis

### Propriedades da estratégia

> demonstração izbicki

### Resultados empíricos

> resultados dos modelos aplicados nos dados

## Modelagem usando verossimilhança {#veross}

Assim como na área de análise de sobrevivência, podemos pensar a informação do oráculo como um problema de dados censurados. Quando o modelo acerta, temos uma observação completa. Quando o modelo erra, temos a informação de que o rótulo testado está incorreto.

Seja $z_i$ o indicador fornecido pelo oráculo de que o rótulo está correto. A verossimilhança do modelo é dada por

$$
\mathcal L(\tt;\mathbf y,\mathbf z)=\prod_i \P(Y=y|\tt)^{z_i}\P(Y\neq y|\tt)^{1-z_i}.
$$

A partir da construção da base definida na Seção \@ref(construcao), podemos ajustar um novo modelo com a base completa, modificando a função de perda para acomodar os dados censurados.

A vantagem da modelagem usando a verossimilhança com dados censurados é que ela considera exatamente a informação que é dada pelo oráculo. Isso evita os potenciais problemas na abordagem via heurísticas, já que em nenhum momento o modelo receberá dados com erros de medição.

A técnica, no entanto, apresenta duas desvantagens.

A primeira é que não existem garantias teóricas de que a técnica produz um classificador melhor que a versão inicial. Diferentemente das suposições comuns em análise de sobrevivência, o mecanismo gerador da censura no nosso caso não é aleatório, já que o gerador de observações censuradas é a função de predição do modelo. Assim, não podemos importar os resultados da área de análise de sobrevivência diretamente.

A segunda é de ordem prática. Como a solução envolve modificações na função de perda, ele não é diretamente adaptável a qualquer modelo estatístico para ajustar os dados de Captchas, precisando ser implementado caso a caso.

### Resultados empíricos

> resultados dos modelos aplicados nos dados

## Implementação

> Conclusão sobre quais são os melhores métodos
>
> comentários adicionais sobre como utilizar
>
> descrição do pacote
>
> a documentação completa do pacote será um apêndice
