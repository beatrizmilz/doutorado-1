$$\newcommand{\x}{\mathbf{x}}
\newcommand{\X}{\mathbf{X}}
\renewcommand{\s}{\mathbf{s}}
\renewcommand{\S}{\mathbf{S}}
\renewcommand{\Z}{\mathbf{Z}}
\renewcommand{\z}{\mathbf{z}}
\newcommand{\w}{\mathbf{w}}
\renewcommand{\P}{\mathbb{P}}
\renewcommand{\tt}{\boldsymbol{\theta}}$$

# Modelagem {#modelo}

Para este trabalho, desenvolvemos uma técnica inovadora para resolver Captchas sem a necessidade de *feedback* humano. A solução envolve avanços em duas direções: engenharia e modelagem.

## Construção dos dados {#construcao}

Na parte de engenharia, desenvolvemos uma técnica para capturar e anotar feedbacks automatizados do oráculo no preenchimento de Captchas. A técnica consiste em três passos:

1.  Desenvolver um robô que acessa o site desejado e tenta acessar uma informação que exige preenchimento de Captcha.
2.  A partir de um modelo estatístico inicial, o robô tenta preencher o Captcha automaticamente, submetendo para avaliação do site.
3.  Se o Captcha for verificado pelo site como correto, anotamos o caminho da imagem com o valor "1". Se estiver incorreto, anotamos o caminho da imagem com o valor "0".

O procedimento descrito pode ser reproduzindo indefinidamente. Isso significa que podemos criar uma base de dados virtualmente infinita de Captchas rotulados, com a informação adicional do rótulo estar correto ou incorreto. Fizemos isso para todos os Captchas presentes em nossa base de dados.

<!-- TODO na verdade tem bastante que da pra testar diferentes -->
Um problema prático do oráculo é sua propriedade de **memória**. Em problemas reais, não é possível testar diferentes rótulos para a mesma imagem, o que inviabiliza o uso de técnicas de força bruta na resolução de Captchas.

Outro problema é que a informação adicional recebida quando o modelo erra é **incompleta**. A única informação nova que temos é que o rótulo testado está incorreto, dentre todos os rótulos possíveis daquela imagem. Como temos uma grande quantidade de rótulos possíveis em um Captcha, muitas vezes na ordem de milhões, o *feedback* do oráculo pode ser considerado fraco.

Uma possível abordagem para lidar com o segundo problema seria simplesmente descartar os Captchas classificados incorretamente. Podemos criar uma base de dados (virtualmente infinita) somente com os rótulos corretos e ajustar um novo modelo. Essa abordagem, no entanto, tem sérios problemas, já que considera somente os casos em que o classificador já funciona bem. Nosso objetivo é melhorar o modelo justamente nos casos em que o oráculo acusa erros.

Fizemos isso de duas formas.

## Modelagem usando heurísticas {#heuristica}

O fato da informação ser incompleta e fraca não significa que ela é inútil. Os Captchas que estamos trabalhando possuem várias letras geradas de forma independente, fazendo com que um classificador $g$ seja na verdade um classificador multivariado:

$$\begin{align*}
g(\X) = (g(\X)_1, g(\X)_2, \dots, g(\X)_k),
\end{align*}$$

sendo $k$ o número de letras do Captcha. Supondo que o classificador é igualmente poderoso para todas as posições das letras, temos que

$$\begin{align*}
p = \P(g(\X) = Y) = \P(g(\X)_1 = Y_1)^k = p_{1}^k
\end{align*}.$$

Seja $N$ a quantidade de acertos de $g(\X)$. Sabemos que $N\sim \text{Bin}(k, p_{1})$. Então, quando o oráculo acusa que o modelo errou, a probabilidade do modelo ter errado somente uma letra é

$$\begin{align*}
\P(\text{errei uma letra}\;|\;\text{errei}) &= \P(N=k-1|N\neq k) \\
&= \frac{(k-1) p_{1}^{k-1} (1-p_{1})}{1-p_1^k}
\end{align*}$$

A Figura \@ref(fig:probabilidades) mostra as probabilidades da equação acima graficamente, considerando $k=5$. Como vimos, é razoável admitir que um modelo inicial teria pelo menos 80% de acurácia para uma letra específica. Nessas condições, quando o oráculo dá um feedback negativo, a probabilidade do modelo ter errado somente uma letra do Captcha é próxima a 50%.

```{r probabilidades, fig.height=4, fig.width=7, fig.cap="Probabilidade do modelo ter errado somente uma letra, a partir de um feedback negativo do oráculo. Considerando um captcha de 5 letras."}
k <- 5
p <- seq(.5, .999, .001)
prob <- (k-1) * p^(k-1) * (1-p) / (1-p^k)
ggplot2::qplot(p, prob, geom = "line") +
  ggplot2::theme_minimal(12) +
  ggplot2::scale_x_continuous(labels = scales::percent) +
  ggplot2::scale_y_continuous(labels = scales::percent) +
  ggplot2::geom_hline(yintercept = 1-1/k, linetype = 2, colour = 2) +
  ggplot2::annotate("text", x = .5, y = 1-1/k, label = "Limite teórico = 1-1/k", vjust = 1.4, hjust = 0, size = 3, colour = 2) +
  ggplot2::labs(
    x = "Probabilidade do modelo acertar uma letra",
    y = "Probabilidade de ter errado somente uma letra\ndado o feedback negativo do oráculo"
  )
```

As intuições apresentadas sugerem duas possibilidades. Por um lado, podemos pensar em uma estratégia para corrigir os dados a partir do feedback do usuário e das probabilidades reportadas pelo modelo de classificação. Chamaremos uma estratégia desse tipo de *heurística*.

### Heurística 1: substituição da pior predição

Uma possível estratégia é substituir a letra com maior incerteza na predição, seguindo os passos abaixo.

1. Dentre todas as letras, selecionamos a que tem a menor probabilidade máxima

$$i_{\text{mudar}}={\arg \min}_{i=1,\dots,k} \max_j \hat p_{ij},$$

em que $\hat p_{ij}$ é a probabilidade estimada da letra $j$ na posição $i$.

2. Substituímos a predição da letra $i_{\text{mudar}}$ pela segunda colocada no vetor $p_{i_{\text{mudar}}\cdot}$.

### Heurística 2: substituição da predição com menor diferença para segunda candidata

A segunda estratégia sugerida é substituir a letra que tem a maior probabilidade mais próxima da segunda maior.

1. Dentre todas as letras, selecionamos a que tem a menor probabilidade máxima.

Primeiro ordenamos as probabilidades dentro de cada letra 

$$\hat p_{i \text{ ord}} = (p_{i\{1\}}, p_{i\{2\}}, \dots, p_{i\{n\}})$$

$$i_{\text{mudar}}={\arg \max}_{i=1,\dots,k} |p_{i\{1\}} - p_{i\{2\}}|$$

2. Substituímos a predição da letra $p_{i\{1\}}$ pela letra com probabilidade $p_{i\{2\}}$.

### Heurística 3: substituição da predição que tem maior entropia no vetor de predições

A terceira estratégia é substituir a letra cujo vetor de predições tem maior entropia.

1. Dentre todas as letras, selecionamos a que tem a maior entropia

$$i_{\text{mudar}}={\arg \max}_{i=1,\dots,k} -\sum_j p_{ij}\log(p_{ij}),$$

2. Substituímos a predição da letra $i_{\text{mudar}}$ pela segunda colocada no vetor $p_{i_{\text{mudar}}\cdot}$.


### Propriedades da estratégia

> demonstração izbicki

### Resultados empíricos

Os resultados empíricos foram divididos em dois testes. Primeiro, separamos uma amostra rotulada para verificar o quanto a heurística recuperava os valores corretos, a partir da predição de um modelo inicial. Depois, verificamos o ganho efetivo na acurácia do modelo alimentado com a base de dados aumentada.

Para o primeiro teste, adotamos o seguinte procedimento. Para cada Captcha, selecionamos bases de treino iniciais que resultaram em acurácias de 40%, 60% e 80% após o ajuste do modelo de redes neurais convolucionais. Em seguida, aplicamos a heurística nos casos da base de teste em que o modelo errou. Finalmente, calculamos o percentual de recuperação dos resultados pela heurística.

A parte do ajuste do modelo de redes neurais convolucionais merece alguns comentários adicionais. Por um lado, é importante que o modelo esteja bem ajustado, para que o erro do modelo seja fruto somente da quantidade de observações e não um problema de sub ajuste. Por outro lado, cada tamanho de base pode estar ligada a diferentes hiperparâmetros, e não existe uma forma de garantir que os melhores hiperparâmetros foram selecionados. 

@goodfellow2014 menciona que, para realizar comparações de modelos, as técnicas de regularização, especialmente aumentação de dados, devem ser padronizadas. Por isso, optamos por manter a mesma grade de hiperparâmetros em todos os modelos. Especificamente, consideramos na grade as quantidades:

- Multiplicador da quantidade de filtros convolucionais. 
- Quantidade de filtros na primeira camada densa.
- Dropout.

Para diferentes modelos, como AC-GAN, o procedimento seria o mesmo. Bastaria fixar os hiperparâmetros e rodar todos os modelos.

A Tabela \@ref(tab:) mostra os resultados da análise. É possível verificar que a heurística X apresenta os melhores resultados, independentemente do Captcha ou da capacidade do modelo inicial.

A Figura \@ref(fig:) mostra os mesmos resultados de forma visual e resumida. É possível notar que a proporção de casos recuperados não aumenta linearmente

Em seguida, passamos para a segunda etapa do procedimento. Nesta etapa, adicionamos a base construída pelo oráculo e modificada pela heurística à base de treino inicial. Como base de teste, utilizamos um conjunto de dados novo, que não foi utilizado em nenhum procedimento anterior, para garantir que não há contaminação


## Modelagem usando verossimilhança {#veross}

Assim como na área de análise de sobrevivência, podemos pensar a informação do oráculo como um problema de dados censurados. Quando o modelo acerta, temos uma observação completa. Quando o modelo erra, temos a informação de que o rótulo testado está incorreto.

Seja $z_i$ o indicador fornecido pelo oráculo de que o rótulo está correto. A verossimilhança do modelo é dada por

$$
\mathcal L(\tt;\mathbf y,\mathbf z)=\prod_i \P(Y=y|\tt)^{z_i}\P(Y\neq y|\tt)^{1-z_i}.
$$

A partir da construção da base definida na Seção \@ref(construcao), podemos ajustar um novo modelo com a base completa, modificando a função de perda para acomodar os dados censurados.

A vantagem da modelagem usando a verossimilhança com dados censurados é que ela considera exatamente a informação que é dada pelo oráculo. Isso evita os potenciais problemas na abordagem via heurísticas, já que em nenhum momento o modelo receberá dados com erros de medição.

A técnica, no entanto, apresenta duas desvantagens.

A primeira é que não existem garantias teóricas de que a técnica produz um classificador melhor que a versão inicial. Diferentemente das suposições comuns em análise de sobrevivência, o mecanismo gerador da censura no nosso caso não é aleatório, já que o gerador de observações censuradas é a função de predição do modelo. Assim, não podemos importar os resultados da área de análise de sobrevivência diretamente.

A segunda é de ordem prática. Como a solução envolve modificações na função de perda, ele não é diretamente adaptável a qualquer modelo estatístico para ajustar os dados de Captchas, precisando ser implementado caso a caso.

### Resultados empíricos

> resultados dos modelos aplicados nos dados

## Implementação

> Conclusão sobre quais são os melhores métodos
>
> comentários adicionais sobre como utilizar
>
> descrição do pacote
>
> a documentação completa do pacote será um apêndice


A implementação da simulação foi feita em três etapas. A primeira etapa 
